{
  "category": "ai-agents",
  "displayName": "AIエージェント",
  "description": "AIエージェントの基礎概念から実装、評価・運用まで体系的に学ぶ。",
  "topics": [
    {
      "id": "agent-topic-overview",
      "term": "AI Agent Overview",
      "termJa": "AIエージェントの概要",
      "meaning": "AIエージェントの定義・特性、ビジネス状況、技術的な位置づけ、開発の選択肢を俯瞰する。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントとは",
            "body": "[[agent-term-ai-agent|AIエージェント]]とは、LLMを頭脳として自律的にタスクを遂行するシステムです。単なるチャットボットがユーザーの質問に1回答えるだけなのに対し、エージェントは目標に向けて複数のステップを計画し、ツールを使い、結果を検証するループを繰り返します。エージェントの特性として、(1)自律性（人間の介入なしに行動できる）、(2)反応性（環境の変化に対応する）、(3)先見性（[[agent-term-planning|計画]]を立てて行動する）、(4)社会性（他のエージェントや人間と協調する）が挙げられます。これらの特性を全て備える必要はなく、タスクに応じて必要な特性を設計に反映します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-planning"]
          },
          {
            "heading": "AIエージェントのビジネス状況と活用例",
            "body": "AIエージェントはカスタマーサポート、データ分析、情報収集、コード生成支援など、幅広い業務で活用が進んでいます。従来のRPA（ロボティック・プロセス・オートメーション）が定型作業の自動化にとどまるのに対し、AIエージェントは非定型な判断を含む業務にも対応できます。企業ではまず社内業務（ヘルプデスク、レポート作成、議事録要約）から導入し、徐々に顧客向けサービスへ展開するパターンが多く見られます。ビジネスでの活用成功の鍵は、エージェントの適用範囲を明確に限定し、[[agent-term-human-in-loop|ヒューマンインザループ]]で人間の監督を組み込むことです。",
            "termRefs": ["agent-term-human-in-loop"]
          },
          {
            "heading": "技術的な位置づけ：LLMからAIエージェントへ",
            "body": "LLMからAIエージェントまでには段階があります。(1)LLM単体：1回の入出力でテキスト生成。(2)LLM + プロンプト設計：[[aidev-term-prompt-engineering|プロンプトエンジニアリング]]で出力を制御。(3)LLM + ツール：[[agent-term-tool-use|ツール呼び出し]]で外部連携。(4)LLM + ツール + 計画：目標達成に向けた自律的な行動。(5)マルチエージェント：複数エージェントの協調。段階が上がるほど能力は増しますが、複雑性とリスクも増大します。エージェントの構築方法には「学習」と「推論」の2つのアプローチがあります。[[agent-term-agent-tuning|エージェントチューニング]]はモデル自体をエージェント行動に最適化する学習アプローチで、推論アプローチはプロンプト設計やワークフロー設計でエージェントを構築します。現在は推論アプローチが主流です。",
            "termRefs": ["aidev-term-prompt-engineering", "agent-term-tool-use", "agent-term-agent-tuning"]
          },
          {
            "heading": "AIエージェント開発の選択肢",
            "body": "エージェントの構築には、(1)フルスクラッチ開発、(2)フレームワーク利用の2つの選択肢があります。代表的なフレームワークとして[[agent-term-langgraph|LangGraph]]（LangChain系、グラフベースのワークフロー定義）、CrewAI（マルチエージェントに特化）、AutoGen（Microsoft、マルチエージェントの会話設計）、OpenAI Agents SDK（OpenAI公式）などがあります。フレームワークを使う利点は開発速度の向上とベストプラクティスの適用ですが、懸念点もあります。抽象化によりデバッグが困難になること、フレームワークの更新に追従が必要なこと、特定のユースケースへの柔軟な対応が難しい場合があることです。プロジェクトの規模・要件・チームのスキルに応じて選択しましょう。",
            "termRefs": ["agent-term-langgraph"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-agent-definition", "agent-concept-agent-business", "agent-concept-llm-to-agent", "agent-concept-framework-choice"]
    },
    {
      "id": "agent-topic-architecture",
      "term": "AI Agent Architecture",
      "termJa": "AIエージェントの構成",
      "meaning": "AIエージェントの内部構成要素（プロフィール、ツール、計画、自己修正、メモリ）とワークフローパターンを理解する。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントの内部構成",
            "body": "[[agent-term-ai-agent|AIエージェント]]の内部は、大きく分けて5つの構成要素で成り立っています。(1)[[agent-term-profile|プロフィール]]：エージェントの役割・専門性の定義。(2)[[agent-term-tool-use|ツール呼び出し]]：外部システムとのインタラクション。(3)[[agent-term-planning|計画]]：タスクの分解と実行順序の決定。(4)[[agent-term-self-correction|自己修正]]：実行結果の検証と修正。(5)[[agent-term-memory|メモリ]]：経験と知識の蓄積。これらを[[agent-term-perception|知覚]]（環境からの入力受信）が支えます。エージェントの「環境」とは、ユーザーインターフェース、利用可能なツール群、アクセス可能なデータソースなど、エージェントが相互作用する全てを指します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-profile", "agent-term-tool-use", "agent-term-planning", "agent-term-self-correction", "agent-term-memory", "agent-term-perception"]
          },
          {
            "heading": "プロフィール（Profile）",
            "body": "[[agent-term-profile|プロフィール]]はエージェントの「人格」を定義するシステムプロンプトです。役割（「あなたはヘルプデスク担当のAIです」）、専門領域、行動指針、出力形式のルールなどを含みます。実装上の注意点として、プロフィールが長すぎるとLLMの注意が分散するため、最も重要な指示を先頭に配置すること。また、禁止事項よりも推奨行動を明記する方が効果的です。[[agent-term-perception|知覚]]の設計も重要で、ユーザー入力のフォーマット変換やマルチモーダル入力（画像・音声）の処理方法をプロフィール内で定義することがあります。",
            "termRefs": ["agent-term-profile", "agent-term-perception"]
          },
          {
            "heading": "ツール呼び出しとMCP",
            "body": "[[agent-term-tool-use|ツール呼び出し]]はエージェントが外部世界に働きかける手段です。LLMが関数名と引数をJSONで出力し、ランタイムが実際の関数を実行して結果をLLMに返します。ツール設計で気を付けたいのは、(1)ツールの説明文を明確にする（LLMはこの説明でツール選択を判断する）、(2)引数の型とバリデーションを厳密にする、(3)ツール数を適度に保つ（多すぎると選択精度が下がる）ことです。[[agent-term-mcp|Model Context Protocol（MCP）]]は、ツール接続を標準化するプロトコルで、USBのように異なるツールを統一的なインターフェースで接続可能にします。MCPにより、ツールの再利用性と相互運用性が大幅に向上します。",
            "termRefs": ["agent-term-tool-use", "agent-term-mcp"]
          },
          {
            "heading": "計画（Planning）",
            "body": "[[agent-term-planning|計画]]はエージェントのタスク分解と実行戦略の決定プロセスです。計画には2つのアプローチがあります。(1)事前計画：タスク全体を最初に分解し、サブタスクのリストを生成する。(2)動的計画：1ステップずつ実行し、結果に応じて次のステップを決定する。[[agent-term-plan-and-execute|Plan-and-Execute型]]は事前計画の代表で、計画フェーズと実行フェーズを明確に分離します。実装上の注意点として、計画が粗すぎると実行時に判断が曖昧になり、細かすぎると計画自体のコストが増大します。また、計画は固定ではなく、実行結果に応じて修正（再計画）できる設計にすることが重要です。",
            "termRefs": ["agent-term-planning", "agent-term-plan-and-execute"]
          },
          {
            "heading": "自己修正（Self-Correction）",
            "body": "[[agent-term-self-correction|自己修正]]はエージェントが自身の出力を検証し、問題を修正するメカニズムです。具体的には、(1)出力の検証（生成したコードの構文チェック、回答の整合性確認）、(2)エラーのリトライ（APIエラー時の再試行、異なるアプローチでの再実行）、(3)[[agent-term-reflection|リフレクション]]（出力を振り返り品質を評価して改善する）の3つが主な手法です。実装上の注意点として、自己修正ループに上限回数を設けないと無限ループに陥るリスクがあります。また、修正の判断基準を明確にすること（何をもって「正しい」とするか）が重要です。",
            "termRefs": ["agent-term-self-correction", "agent-term-reflection"]
          },
          {
            "heading": "メモリ（Memory）",
            "body": "[[agent-term-memory|メモリ]]はエージェントが情報を保持・活用する仕組みです。(1)短期メモリ：現在の会話やタスクのコンテキスト。LLMのコンテキストウィンドウに相当し、会話が長くなると古い情報が失われる。(2)長期メモリ：永続化された知識・経験。ベクトルデータベースやファイルに保存し、必要時に検索して活用する。実装上の注意点として、短期メモリの管理では重要な情報の要約や優先度付けが必要です。長期メモリでは、保存する情報の選別基準と検索の精度が品質を左右します。メモリは[[agent-term-arch-self-improvement|エージェントの自己改善]]にも活用でき、過去の成功・失敗パターンから学習することで継続的にパフォーマンスを向上させます。",
            "termRefs": ["agent-term-memory", "agent-term-arch-self-improvement"]
          },
          {
            "heading": "ワークフロー：シングルとマルチエージェント",
            "body": "[[agent-term-single-agent|シングルエージェントワークフロー]]は1つのエージェントが全処理を担当します。コード生成→実行→検証のサイクルが典型例で、シンプルで管理しやすい反面、複雑なタスクには限界があります。実装上の注意点は、ループ回数の上限設定と、各ステップの入出力の型を明確にすることです。[[agent-term-multi-agent|マルチエージェントワークフロー]]は複数の専門エージェントが協調します。パターンとして、(1)オーケストレーター型：1つの統括エージェントが他を指揮、(2)議論型：エージェント同士が議論して合意形成、(3)階層型：上位が計画、下位が実行。実装上の注意点は、エージェント間の通信プロトコルの統一、デッドロック防止、全体の状態管理です。[[agent-term-ai-workflow|AIワークフロー]]はエージェントほど自律的ではなく、事前定義されたフローに沿って処理する仕組みで、予測可能性が高いのが特徴です。推論モデル（o1等）はエージェントの計画・推論フェーズで特に有効ですが、応答速度とコストのトレードオフを考慮する必要があります。",
            "termRefs": ["agent-term-single-agent", "agent-term-multi-agent", "agent-term-ai-workflow"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-internal-architecture", "agent-concept-profile-design", "agent-concept-tool-design", "agent-concept-planning-strategy", "agent-concept-self-correction-pattern", "agent-concept-memory-design", "agent-concept-workflow-patterns"]
    }
  ],
  "concepts": [
    {
      "id": "agent-concept-agent-definition",
      "term": "Agent Definition & Characteristics",
      "termJa": "エージェントの定義と特性",
      "topicId": "agent-topic-overview",
      "meaning": "AIエージェントの定義（自律的なタスク遂行システム）と4つの特性（自律性、反応性、先見性、社会性）の理解。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-planning"]
    },
    {
      "id": "agent-concept-agent-business",
      "term": "Agent Business Applications",
      "termJa": "エージェントのビジネス活用",
      "topicId": "agent-topic-overview",
      "meaning": "カスタマーサポート、データ分析、情報収集などのビジネス活用パターンと、社内業務から顧客向けサービスへの展開戦略。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-human-in-loop"]
    },
    {
      "id": "agent-concept-llm-to-agent",
      "term": "From LLM to Agent",
      "termJa": "LLMからエージェントへの段階",
      "topicId": "agent-topic-overview",
      "meaning": "LLM単体→プロンプト設計→ツール連携→計画付き自律行動→マルチエージェントという5段階の技術発展。学習アプローチと推論アプローチの違い。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-agent-tuning"]
    },
    {
      "id": "agent-concept-framework-choice",
      "term": "Framework Selection",
      "termJa": "フレームワークの選択",
      "topicId": "agent-topic-overview",
      "meaning": "LangGraph、CrewAI、AutoGen等のエージェントフレームワークの比較と、フルスクラッチとフレームワーク利用の判断基準。",
      "relatedTermIds": ["agent-term-langgraph"]
    },
    {
      "id": "agent-concept-internal-architecture",
      "term": "Internal Architecture",
      "termJa": "内部アーキテクチャ",
      "topicId": "agent-topic-architecture",
      "meaning": "プロフィール・ツール・計画・自己修正・メモリの5要素と知覚から成るエージェントの内部構成。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-profile", "agent-term-tool-use", "agent-term-planning", "agent-term-memory"]
    },
    {
      "id": "agent-concept-profile-design",
      "term": "Profile Design",
      "termJa": "プロフィール設計",
      "topicId": "agent-topic-architecture",
      "meaning": "エージェントの役割・専門性・行動指針をシステムプロンプトとして定義する設計手法。知覚の設計を含む。",
      "relatedTermIds": ["agent-term-profile", "agent-term-perception"]
    },
    {
      "id": "agent-concept-tool-design",
      "term": "Tool Design & MCP",
      "termJa": "ツール設計とMCP",
      "topicId": "agent-topic-architecture",
      "meaning": "ツール呼び出しの実装方法、ツール説明文の設計、MCPによるツール接続の標準化。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-mcp"]
    },
    {
      "id": "agent-concept-planning-strategy",
      "term": "Planning Strategy",
      "termJa": "計画戦略",
      "topicId": "agent-topic-architecture",
      "meaning": "事前計画と動的計画の2つのアプローチ、Plan-and-Execute型の設計、再計画の仕組み。",
      "relatedTermIds": ["agent-term-planning", "agent-term-plan-and-execute"]
    },
    {
      "id": "agent-concept-self-correction-pattern",
      "term": "Self-Correction Patterns",
      "termJa": "自己修正パターン",
      "topicId": "agent-topic-architecture",
      "meaning": "出力検証、リトライ、リフレクションの3つの自己修正手法と、無限ループ防止の設計。",
      "relatedTermIds": ["agent-term-self-correction", "agent-term-reflection"]
    },
    {
      "id": "agent-concept-memory-design",
      "term": "Memory Design",
      "termJa": "メモリ設計",
      "topicId": "agent-topic-architecture",
      "meaning": "短期メモリと長期メモリの使い分け、情報の選別・保存・検索の設計、自己改善への活用。",
      "relatedTermIds": ["agent-term-memory", "agent-term-arch-self-improvement"]
    },
    {
      "id": "agent-concept-workflow-patterns",
      "term": "Workflow Patterns",
      "termJa": "ワークフローパターン",
      "topicId": "agent-topic-architecture",
      "meaning": "シングルエージェントとマルチエージェントのワークフロー設計パターン。オーケストレーター型、議論型、階層型。",
      "relatedTermIds": ["agent-term-single-agent", "agent-term-multi-agent", "agent-term-ai-workflow"]
    }
  ],
  "terms": [
    {
      "id": "agent-term-ai-agent",
      "term": "AI Agent",
      "termJa": "AIエージェント",
      "meaning": "LLMを頭脳として、外部ツールの利用・計画の立案・自己修正を自律的に行い、与えられた目標を達成するソフトウェアシステム。単なるチャットボットと異なり、環境を認識し、判断し、行動するループを持つ。",
      "type": "theory",
      "tags": ["基礎", "全章"]
    },
    {
      "id": "agent-term-profile",
      "term": "Agent Profile",
      "termJa": "エージェントプロフィール",
      "meaning": "エージェントの役割・性格・専門領域・行動指針をシステムプロンプトとして定義したもの。プロフィール設計がエージェントの振る舞いの質を大きく左右する。",
      "type": "theory",
      "tags": ["設計", "構成要素"]
    },
    {
      "id": "agent-term-tool-use",
      "term": "Tool Use / Function Calling",
      "termJa": "ツール呼び出し",
      "meaning": "LLMが外部のAPI・データベース・検索エンジン等のツールを呼び出す機能。LLMが「どのツールを」「どの引数で」呼ぶかをJSON形式で出力し、実行結果をLLMに返すことで、LLM単体ではできない操作を実現する。",
      "type": "technique",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-planning",
      "term": "Planning",
      "termJa": "計画（プランニング）",
      "meaning": "エージェントが目標達成のために、タスクを分解し実行順序を決定するプロセス。計画の質がエージェント全体の成否を左右する。事前計画と動的再計画の2種類がある。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-self-correction",
      "term": "Self-Correction",
      "termJa": "自己修正",
      "meaning": "エージェントが自身の出力や行動の結果を評価し、誤りを検出して修正するメカニズム。リトライ、出力の再検証、代替手段への切り替えなどの戦略がある。",
      "type": "technique",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-memory",
      "term": "Agent Memory",
      "termJa": "エージェントメモリ",
      "meaning": "エージェントが過去の経験・会話履歴・学習した知識を保持する仕組み。短期メモリ（現在の会話コンテキスト）と長期メモリ（永続化された知識・経験）に分かれる。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-perception",
      "term": "Perception",
      "termJa": "知覚",
      "meaning": "エージェントが環境からの情報（ユーザー入力、ツール実行結果、外部データ）を受け取り解釈するプロセス。マルチモーダル入力（テキスト・画像・音声）の処理も含む。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-agent-tuning",
      "term": "Agent-Tuning",
      "termJa": "エージェントチューニング",
      "meaning": "LLMをエージェントタスクに特化してファインチューニングする手法。ツール呼び出しの精度向上、計画能力の強化などを目的とし、エージェント行動のトレースデータで学習する。推論時のプロンプト設計とは異なるアプローチ。",
      "type": "technique",
      "tags": ["理論", "学習"]
    },
    {
      "id": "agent-term-single-agent",
      "term": "Single-Agent Workflow",
      "termJa": "シングルエージェントワークフロー",
      "meaning": "1つのエージェントが全ての処理を担当するワークフロー。シンプルで管理しやすいが、複雑なタスクでは限界がある。コード生成→実行→リフレクションのサイクルが典型例。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-multi-agent",
      "term": "Multi-Agent Workflow",
      "termJa": "マルチエージェントワークフロー",
      "meaning": "複数の専門エージェントが協調してタスクを遂行するワークフロー。各エージェントに異なる役割を割り当て、連携させることで複雑な問題に対応する。オーケストレーター型、議論型、階層型などのパターンがある。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-chat-completions",
      "term": "Chat Completions API",
      "termJa": "チャット補完API",
      "meaning": "OpenAI等が提供する、会話形式でLLMを呼び出すAPI。system/user/assistantのロールでメッセージを送り、AIの応答を得る。エージェント開発の基盤となるインターフェース。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-reasoning-models",
      "term": "Reasoning Models",
      "termJa": "推論モデル",
      "meaning": "o1、o3等の、内部で段階的な推論プロセスを実行するLLM。通常のモデルより複雑な論理的思考が可能で、計画立案や数学的推論に優れる。エージェントの計画フェーズでの活用が期待される。",
      "type": "theory",
      "tags": ["モデル", "理論"]
    },
    {
      "id": "agent-term-structured-outputs",
      "term": "Structured Outputs",
      "termJa": "構造化出力",
      "meaning": "LLMの出力をJSONスキーマ等の事前定義された形式に強制する機能。エージェントのツール呼び出しや計画出力で、パース可能な安定した出力を保証する。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-prompt-caching",
      "term": "Prompt Caching",
      "termJa": "プロンプトキャッシング",
      "meaning": "同一のプロンプトプレフィックスを再利用し、API呼び出しのコストと遅延を削減する技術。長いシステムプロンプトや大量のコンテキストを使うエージェントで特に有効。",
      "type": "technique",
      "tags": ["開発", "最適化"]
    },
    {
      "id": "agent-term-code-interpreter",
      "term": "Code Interpreter",
      "termJa": "コードインタープリタ",
      "meaning": "AIが生成したプログラムコードをサンドボックス環境で実行し、結果を取得する仕組み。データ分析、数値計算、ファイル変換など、LLMの計算能力を補完するツールとして使われる。",
      "type": "technique",
      "tags": ["ツール", "実行環境"]
    },
    {
      "id": "agent-term-embedding-api",
      "term": "Embedding API",
      "termJa": "エンベディングAPI",
      "meaning": "テキストをベクトル（数値の配列）に変換するAPI。意味的に近いテキスト同士が近いベクトルになる性質を利用し、セマンティック検索やRAGの基盤技術として使われる。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-assistants-api",
      "term": "Assistants API",
      "termJa": "アシスタントAPI",
      "meaning": "OpenAIが提供する、ステートフルなAIアシスタントを構築するためのAPI。スレッド管理、ファイル処理、Code Interpreter、Function Callingを統合的に提供する。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-langgraph",
      "term": "LangGraph",
      "termJa": "LangGraph",
      "meaning": "LangChainチームが開発した、グラフベースのエージェントワークフロー構築フレームワーク。ステートマシンとしてエージェントの状態遷移を定義し、条件分岐・ループ・人間の介入を含む複雑なワークフローを構築できる。",
      "type": "technique",
      "tags": ["フレームワーク", "開発"]
    },
    {
      "id": "agent-term-mcp",
      "term": "Model Context Protocol (MCP)",
      "termJa": "モデルコンテキストプロトコル",
      "meaning": "Anthropicが提唱する、AIモデルと外部ツール・データソースを標準的な方法で接続するオープンプロトコル。USBのように、様々なツールをエージェントに統一的なインターフェースで接続できる。",
      "type": "technique",
      "tags": ["プロトコル", "ツール"]
    },
    {
      "id": "agent-term-plan-and-execute",
      "term": "Plan-and-Execute",
      "termJa": "計画実行型",
      "meaning": "まず全体計画を立て、その計画に基づいてサブタスクを順次実行するエージェントパターン。計画フェーズと実行フェーズを分離することで、複雑なタスクを体系的に処理する。実行結果に応じた計画の修正（再計画）も含む。",
      "type": "technique",
      "tags": ["パターン", "設計"]
    },
    {
      "id": "agent-term-reflection",
      "term": "Reflection",
      "termJa": "リフレクション",
      "meaning": "エージェントが自身の出力を振り返り、品質を評価・改善するプロセス。コード生成後にエラーを検出して修正する、回答の正確性を自己チェックするなど。自己修正の具体的な実装手法の一つ。",
      "type": "technique",
      "tags": ["パターン", "品質"]
    },
    {
      "id": "agent-term-e2b",
      "term": "E2B (Code Sandbox)",
      "termJa": "E2B（コードサンドボックス）",
      "meaning": "AIが生成したコードを安全に実行するためのクラウドサンドボックス環境。ホストシステムから隔離された環境でコードを実行し、結果を取得する。データ分析エージェントでの活用が代表的。",
      "type": "technique",
      "tags": ["ツール", "実行環境"]
    },
    {
      "id": "agent-term-langgraph-studio",
      "term": "LangGraph Studio",
      "termJa": "LangGraph Studio",
      "meaning": "LangGraphで構築したエージェントワークフローを視覚的にデバッグ・テストするためのツール。グラフの状態遷移をリアルタイムで確認でき、各ノードの入出力を検査できる。",
      "type": "technique",
      "tags": ["ツール", "デバッグ"]
    },
    {
      "id": "agent-term-local-llm",
      "term": "Local LLM",
      "termJa": "ローカルLLM",
      "meaning": "Ollama等を使いローカル環境で動作させるLLM。API費用がかからず、データがローカルに留まるため機密性が高い。ただし、モデルサイズやGPUリソースによる性能の制約がある。",
      "type": "technique",
      "tags": ["開発", "モデル"]
    },
    {
      "id": "agent-term-ai-workflow",
      "term": "AI Workflow",
      "termJa": "AIワークフロー",
      "meaning": "LLMの呼び出しとツール実行を、事前定義されたフローに基づいて制御する仕組み。エージェントほど自律的ではないが、予測可能性が高く、特定の業務プロセスの自動化に適している。エージェントの構成要素としても使われる。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-evaluation",
      "term": "Agent Evaluation",
      "termJa": "エージェント評価",
      "meaning": "AIエージェントの性能を定量的・定性的に評価するプロセス。エージェント能力（ツール使用、計画、記憶）と問題解決能力（タスクの完了度、正確性）の2軸で評価する。",
      "type": "theory",
      "tags": ["評価", "運用"]
    },
    {
      "id": "agent-term-llm-judge",
      "term": "LLM-as-a-Judge",
      "termJa": "LLMによる評価",
      "meaning": "LLM自体を評価者として使い、エージェントの出力品質を自動評価する手法。人間の評価と相関が高い場合が多く、大量のテストケースの評価を効率化できる。ただし、評価LLM自体のバイアスに注意が必要。",
      "type": "technique",
      "tags": ["評価", "手法"]
    },
    {
      "id": "agent-term-task-domain-space",
      "term": "Task Space / Domain Space",
      "termJa": "タスク空間・ドメイン空間",
      "meaning": "エージェントの評価における2つの次元。タスク空間はエージェントが解くべき問題の種類と複雑さ、ドメイン空間は業務領域固有の知識や制約を表す。評価設計時に両方をカバーすることが重要。",
      "type": "theory",
      "tags": ["評価", "理論"]
    },
    {
      "id": "agent-term-error-analysis",
      "term": "Error Analysis",
      "termJa": "エラー分析",
      "meaning": "エージェントの失敗パターンを体系的に分類・分析する手法。計画・推論エラー、行動・実行エラー、環境・知覚エラー、マルチエージェント連携エラーの4カテゴリで整理し、改善に活かす。",
      "type": "technique",
      "tags": ["評価", "改善"]
    },
    {
      "id": "agent-term-agent-ux",
      "term": "Agent UX",
      "termJa": "エージェントUX",
      "meaning": "AIエージェントとユーザーの間のインタラクション設計。エージェントの処理過程の可視化、信頼性の構築、ユーザーの承認・介入ポイントの設計など、従来のUI/UXとは異なる設計原則が求められる。",
      "type": "theory",
      "tags": ["運用", "UX"]
    },
    {
      "id": "agent-term-prompt-injection",
      "term": "Prompt Injection",
      "termJa": "プロンプトインジェクション",
      "meaning": "悪意のある入力によってエージェントの指示を上書きし、意図しない動作を引き起こす攻撃手法。間接的プロンプトインジェクション（外部データ経由）は特に防御が難しく、エージェントのセキュリティ設計で最重要課題の一つ。",
      "type": "theory",
      "tags": ["セキュリティ", "リスク"]
    },
    {
      "id": "agent-term-agentops",
      "term": "AgentOps",
      "termJa": "AgentOps",
      "meaning": "AIエージェントの運用を監視・管理するための概念・ツール群。エージェントの実行トレース、コスト追跡、パフォーマンス計測、異常検知などを包括的に行う。MLOpsのエージェント版。",
      "type": "technique",
      "tags": ["運用", "モニタリング"]
    },
    {
      "id": "agent-term-langsmith",
      "term": "LangSmith",
      "termJa": "LangSmith",
      "meaning": "LangChainチームが提供する、LLMアプリケーションの開発・テスト・モニタリングプラットフォーム。エージェントの実行トレースの可視化、プロンプトの管理、評価データセットの作成・実行が可能。",
      "type": "technique",
      "tags": ["ツール", "モニタリング"]
    },
    {
      "id": "agent-term-prompt-flow-tracing",
      "term": "Prompt Flow Tracing",
      "termJa": "Prompt Flow トレーシング",
      "meaning": "Microsoftが提供するPrompt flowのトレース機能。エージェントの各ステップ（LLM呼び出し、ツール実行、判断分岐）をDAGとして可視化し、ボトルネックの特定やデバッグに活用する。",
      "type": "technique",
      "tags": ["ツール", "モニタリング"]
    },
    {
      "id": "agent-term-human-in-loop",
      "term": "Human-in-the-Loop",
      "termJa": "ヒューマンインザループ",
      "meaning": "エージェントの処理フローに人間の判断・承認ポイントを組み込む設計パターン。重要な意思決定や不可逆な操作の前に人間の確認を挟むことで、エージェントの安全性と信頼性を確保する。",
      "type": "technique",
      "tags": ["設計", "安全性"]
    },
    {
      "id": "agent-term-guardrails",
      "term": "Guardrails",
      "termJa": "ガードレール",
      "meaning": "エージェントの行動を安全な範囲内に制限する仕組み。入力のフィルタリング、出力の検証、許可されたアクションのホワイトリスト、コスト上限の設定など、多層的な防御を構築する。",
      "type": "technique",
      "tags": ["安全性", "運用"]
    },
    {
      "id": "agent-term-arch-self-improvement",
      "term": "Agent Architecture Self-Improvement",
      "termJa": "エージェントの自己改善",
      "meaning": "エージェントが運用中の経験から学び、プロンプト・ツール選択・ワークフロー自体を改善する仕組み。メモリに蓄積された成功・失敗パターンを活用し、継続的にパフォーマンスを向上させる。",
      "type": "technique",
      "tags": ["運用", "改善"]
    },
    {
      "id": "agent-term-role-playing",
      "term": "Role-Playing Agent",
      "termJa": "ロールプレイングエージェント",
      "meaning": "特定の人物像（ペルソナ）の役割を演じるエージェント。マーケティングではターゲット顧客を模擬し、コンテンツの評価やフィードバックを行う。複数ペルソナのエージェントによるディスカッションも可能。",
      "type": "technique",
      "tags": ["パターン", "活用"]
    },
    {
      "id": "agent-term-personalization",
      "term": "Personalization Agent",
      "termJa": "パーソナライズエージェント",
      "meaning": "ユーザーの属性・行動履歴・嗜好に基づき、個別最適化された提案やコンテンツを生成するエージェント。会話を通じてユーザーの潜在ニーズを把握し、従来のルールベースを超えた柔軟なレコメンドを実現する。",
      "type": "technique",
      "tags": ["パターン", "活用"]
    },
    {
      "id": "agent-term-rag-long-context",
      "term": "RAG + Long Context",
      "termJa": "RAGとロングコンテキスト",
      "meaning": "RAG（検索拡張生成）とロングコンテキストモデルの使い分け・併用戦略。ロングコンテキストモデルは大量のテキストを直接入力できるが、コストが高い。RAGは必要な情報のみを検索するため効率的だが、検索精度に依存する。",
      "type": "technique",
      "tags": ["技術", "検索"]
    }
  ]
}
