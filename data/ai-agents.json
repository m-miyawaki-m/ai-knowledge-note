{
  "category": "ai-agents",
  "displayName": "AIエージェント",
  "description": "AIエージェントの基礎概念から実装、評価・運用まで体系的に学ぶ。",
  "topics": [
    {
      "id": "agent-topic-overview",
      "term": "AI Agent Overview",
      "termJa": "AIエージェントの概要",
      "meaning": "AIエージェントの定義・特性、ビジネス状況、技術的な位置づけ、開発の選択肢を俯瞰する。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントとは",
            "body": "[[agent-term-ai-agent|AIエージェント]]とは、LLMを頭脳として自律的にタスクを遂行するシステムです。単なるチャットボットがユーザーの質問に1回答えるだけなのに対し、エージェントは目標に向けて複数のステップを計画し、ツールを使い、結果を検証するループを繰り返します。エージェントの特性として、(1)自律性（人間の介入なしに行動できる）、(2)反応性（環境の変化に対応する）、(3)先見性（[[agent-term-planning|計画]]を立てて行動する）、(4)社会性（他のエージェントや人間と協調する）が挙げられます。これらの特性を全て備える必要はなく、タスクに応じて必要な特性を設計に反映します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-planning"]
          },
          {
            "heading": "AIエージェントのビジネス状況と活用例",
            "body": "AIエージェントはカスタマーサポート、データ分析、情報収集、コード生成支援など、幅広い業務で活用が進んでいます。従来のRPA（ロボティック・プロセス・オートメーション）が定型作業の自動化にとどまるのに対し、AIエージェントは非定型な判断を含む業務にも対応できます。企業ではまず社内業務（ヘルプデスク、レポート作成、議事録要約）から導入し、徐々に顧客向けサービスへ展開するパターンが多く見られます。ビジネスでの活用成功の鍵は、エージェントの適用範囲を明確に限定し、[[agent-term-human-in-loop|ヒューマンインザループ]]で人間の監督を組み込むことです。",
            "termRefs": ["agent-term-human-in-loop"]
          },
          {
            "heading": "技術的な位置づけ：LLMからAIエージェントへ",
            "body": "LLMからAIエージェントまでには段階があります。(1)LLM単体：1回の入出力でテキスト生成。(2)LLM + プロンプト設計：[[aidev-term-prompt-engineering|プロンプトエンジニアリング]]で出力を制御。(3)LLM + ツール：[[agent-term-tool-use|ツール呼び出し]]で外部連携。(4)LLM + ツール + 計画：目標達成に向けた自律的な行動。(5)マルチエージェント：複数エージェントの協調。段階が上がるほど能力は増しますが、複雑性とリスクも増大します。エージェントの構築方法には「学習」と「推論」の2つのアプローチがあります。[[agent-term-agent-tuning|エージェントチューニング]]はモデル自体をエージェント行動に最適化する学習アプローチで、推論アプローチはプロンプト設計やワークフロー設計でエージェントを構築します。現在は推論アプローチが主流です。",
            "termRefs": ["aidev-term-prompt-engineering", "agent-term-tool-use", "agent-term-agent-tuning"]
          },
          {
            "heading": "AIエージェント開発の選択肢",
            "body": "エージェントの構築には、(1)フルスクラッチ開発、(2)フレームワーク利用の2つの選択肢があります。代表的なフレームワークとして[[agent-term-langgraph|LangGraph]]（LangChain系、グラフベースのワークフロー定義）、CrewAI（マルチエージェントに特化）、AutoGen（Microsoft、マルチエージェントの会話設計）、OpenAI Agents SDK（OpenAI公式）などがあります。フレームワークを使う利点は開発速度の向上とベストプラクティスの適用ですが、懸念点もあります。抽象化によりデバッグが困難になること、フレームワークの更新に追従が必要なこと、特定のユースケースへの柔軟な対応が難しい場合があることです。プロジェクトの規模・要件・チームのスキルに応じて選択しましょう。",
            "termRefs": ["agent-term-langgraph"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-agent-definition", "agent-concept-agent-business", "agent-concept-llm-to-agent", "agent-concept-framework-choice"]
    },
    {
      "id": "agent-topic-architecture",
      "term": "AI Agent Architecture",
      "termJa": "AIエージェントの構成",
      "meaning": "AIエージェントの内部構成要素（プロフィール、ツール、計画、自己修正、メモリ）とワークフローパターンを理解する。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントの内部構成",
            "body": "[[agent-term-ai-agent|AIエージェント]]の内部は、大きく分けて5つの構成要素で成り立っています。(1)[[agent-term-profile|プロフィール]]：エージェントの役割・専門性の定義。(2)[[agent-term-tool-use|ツール呼び出し]]：外部システムとのインタラクション。(3)[[agent-term-planning|計画]]：タスクの分解と実行順序の決定。(4)[[agent-term-self-correction|自己修正]]：実行結果の検証と修正。(5)[[agent-term-memory|メモリ]]：経験と知識の蓄積。これらを[[agent-term-perception|知覚]]（環境からの入力受信）が支えます。エージェントの「環境」とは、ユーザーインターフェース、利用可能なツール群、アクセス可能なデータソースなど、エージェントが相互作用する全てを指します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-profile", "agent-term-tool-use", "agent-term-planning", "agent-term-self-correction", "agent-term-memory", "agent-term-perception"]
          },
          {
            "heading": "プロフィール（Profile）",
            "body": "[[agent-term-profile|プロフィール]]はエージェントの「人格」を定義するシステムプロンプトです。役割（「あなたはヘルプデスク担当のAIです」）、専門領域、行動指針、出力形式のルールなどを含みます。実装上の注意点として、プロフィールが長すぎるとLLMの注意が分散するため、最も重要な指示を先頭に配置すること。また、禁止事項よりも推奨行動を明記する方が効果的です。[[agent-term-perception|知覚]]の設計も重要で、ユーザー入力のフォーマット変換やマルチモーダル入力（画像・音声）の処理方法をプロフィール内で定義することがあります。",
            "termRefs": ["agent-term-profile", "agent-term-perception"]
          },
          {
            "heading": "ツール呼び出しとMCP",
            "body": "[[agent-term-tool-use|ツール呼び出し]]はエージェントが外部世界に働きかける手段です。LLMが関数名と引数をJSONで出力し、ランタイムが実際の関数を実行して結果をLLMに返します。ツール設計で気を付けたいのは、(1)ツールの説明文を明確にする（LLMはこの説明でツール選択を判断する）、(2)引数の型とバリデーションを厳密にする、(3)ツール数を適度に保つ（多すぎると選択精度が下がる）ことです。[[agent-term-mcp|Model Context Protocol（MCP）]]は、ツール接続を標準化するプロトコルで、USBのように異なるツールを統一的なインターフェースで接続可能にします。MCPにより、ツールの再利用性と相互運用性が大幅に向上します。",
            "termRefs": ["agent-term-tool-use", "agent-term-mcp"]
          },
          {
            "heading": "計画（Planning）",
            "body": "[[agent-term-planning|計画]]はエージェントのタスク分解と実行戦略の決定プロセスです。計画には2つのアプローチがあります。(1)事前計画：タスク全体を最初に分解し、サブタスクのリストを生成する。(2)動的計画：1ステップずつ実行し、結果に応じて次のステップを決定する。[[agent-term-plan-and-execute|Plan-and-Execute型]]は事前計画の代表で、計画フェーズと実行フェーズを明確に分離します。実装上の注意点として、計画が粗すぎると実行時に判断が曖昧になり、細かすぎると計画自体のコストが増大します。また、計画は固定ではなく、実行結果に応じて修正（再計画）できる設計にすることが重要です。",
            "termRefs": ["agent-term-planning", "agent-term-plan-and-execute"]
          },
          {
            "heading": "自己修正（Self-Correction）",
            "body": "[[agent-term-self-correction|自己修正]]はエージェントが自身の出力を検証し、問題を修正するメカニズムです。具体的には、(1)出力の検証（生成したコードの構文チェック、回答の整合性確認）、(2)エラーのリトライ（APIエラー時の再試行、異なるアプローチでの再実行）、(3)[[agent-term-reflection|リフレクション]]（出力を振り返り品質を評価して改善する）の3つが主な手法です。実装上の注意点として、自己修正ループに上限回数を設けないと無限ループに陥るリスクがあります。また、修正の判断基準を明確にすること（何をもって「正しい」とするか）が重要です。",
            "termRefs": ["agent-term-self-correction", "agent-term-reflection"]
          },
          {
            "heading": "メモリ（Memory）",
            "body": "[[agent-term-memory|メモリ]]はエージェントが情報を保持・活用する仕組みです。(1)短期メモリ：現在の会話やタスクのコンテキスト。LLMのコンテキストウィンドウに相当し、会話が長くなると古い情報が失われる。(2)長期メモリ：永続化された知識・経験。ベクトルデータベースやファイルに保存し、必要時に検索して活用する。実装上の注意点として、短期メモリの管理では重要な情報の要約や優先度付けが必要です。長期メモリでは、保存する情報の選別基準と検索の精度が品質を左右します。メモリは[[agent-term-arch-self-improvement|エージェントの自己改善]]にも活用でき、過去の成功・失敗パターンから学習することで継続的にパフォーマンスを向上させます。",
            "termRefs": ["agent-term-memory", "agent-term-arch-self-improvement"]
          },
          {
            "heading": "ワークフロー：シングルとマルチエージェント",
            "body": "[[agent-term-single-agent|シングルエージェントワークフロー]]は1つのエージェントが全処理を担当します。コード生成→実行→検証のサイクルが典型例で、シンプルで管理しやすい反面、複雑なタスクには限界があります。実装上の注意点は、ループ回数の上限設定と、各ステップの入出力の型を明確にすることです。[[agent-term-multi-agent|マルチエージェントワークフロー]]は複数の専門エージェントが協調します。パターンとして、(1)オーケストレーター型：1つの統括エージェントが他を指揮、(2)議論型：エージェント同士が議論して合意形成、(3)階層型：上位が計画、下位が実行。実装上の注意点は、エージェント間の通信プロトコルの統一、デッドロック防止、全体の状態管理です。[[agent-term-ai-workflow|AIワークフロー]]はエージェントほど自律的ではなく、事前定義されたフローに沿って処理する仕組みで、予測可能性が高いのが特徴です。推論モデル（o1等）はエージェントの計画・推論フェーズで特に有効ですが、応答速度とコストのトレードオフを考慮する必要があります。",
            "termRefs": ["agent-term-single-agent", "agent-term-multi-agent", "agent-term-ai-workflow"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-internal-architecture", "agent-concept-profile-design", "agent-concept-tool-design", "agent-concept-planning-strategy", "agent-concept-self-correction-pattern", "agent-concept-memory-design", "agent-concept-workflow-patterns"]
    },
    {
      "id": "agent-topic-dev-setup",
      "term": "Development Setup",
      "termJa": "開発準備",
      "meaning": "AIエージェント開発に必要なAPI・ツール・フレームワークの基礎知識。Chat Completions APIからLangGraphまで。",
      "article": {
        "sections": [
          {
            "heading": "Chat Completions APIとモデルの基本",
            "body": "エージェント開発の出発点は[[agent-term-chat-completions|Chat Completions API]]です。system（システム指示）、user（ユーザー入力）、assistant（AI応答）のロールでメッセージを送り、AIの応答を得ます。代表的なモデルとして、GPT-4o（高性能・マルチモーダル）、GPT-4o-mini（高速・低コスト）などがあり、タスクの要件に応じて選択します。[[agent-term-reasoning-models|推論モデル]]（o1、o3等）は内部で段階的な推論を行い、複雑な論理的思考が可能です。エージェントの計画フェーズでの活用が期待されますが、応答速度が遅くコストも高いため、計画など高度な推論が必要な場面に限定して使うのが効果的です。",
            "termRefs": ["agent-term-chat-completions", "agent-term-reasoning-models"]
          },
          {
            "heading": "構造化出力とPrompt Caching",
            "body": "[[agent-term-structured-outputs|構造化出力]]は、LLMの出力をJSONスキーマに従った形式で強制する機能です。エージェントではツール呼び出しの引数や計画の出力で必須の機能で、パース失敗のリスクを排除します。[[agent-term-prompt-caching|プロンプトキャッシング]]は、同一のプロンプトプレフィックス（システムプロンプトや大きなコンテキスト）をキャッシュし、API呼び出しのコストと遅延を削減します。エージェントは同じシステムプロンプトで何度もAPIを呼ぶため、この最適化の効果が大きくなります。",
            "termRefs": ["agent-term-structured-outputs", "agent-term-prompt-caching"]
          },
          {
            "heading": "Function Callingとエージェント用ツール",
            "body": "[[agent-term-tool-use|Function Calling]]はLLMが外部関数を呼び出す機能で、エージェントのツール利用の基盤です。APIリクエストにツールの定義（名前・説明・引数スキーマ）を含めると、LLMは適切なタイミングでツール呼び出しをJSON形式で返します。エージェントでよく使われるツールとして、(1)Web検索：最新情報の取得、(2)RAG（非公開情報の検索）：社内ドキュメントやマニュアルの検索に[[agent-term-embedding-api|Embedding API]]でベクトル化した情報を使う、(3)[[agent-term-code-interpreter|Code Interpreter]]：生成したコードの実行。[[agent-term-assistants-api|Assistants API]]はこれらを統合的に提供するOpenAIのAPIです。",
            "termRefs": ["agent-term-tool-use", "agent-term-embedding-api", "agent-term-code-interpreter", "agent-term-assistants-api"]
          },
          {
            "heading": "LangGraphによるワークフロー構築",
            "body": "[[agent-term-langgraph|LangGraph]]はグラフベースのエージェントワークフロー構築フレームワークです。ステート（状態）を定義し、ノード（処理）とエッジ（遷移）でワークフローを構築します。条件分岐（conditional edge）により、LLMの判断結果に応じてフローを動的に切り替えられます。基本的な構築手順は、(1)State型の定義、(2)各ノード関数の実装、(3)グラフの構築（ノード追加→エッジ定義）、(4)コンパイル→実行。LangGraphの利点は、複雑なループや分岐を含むワークフローを宣言的に定義できること、状態のスナップショットによるデバッグのしやすさ、[[agent-term-human-in-loop|ヒューマンインザループ]]の組み込みが容易なことです。",
            "termRefs": ["agent-term-langgraph", "agent-term-human-in-loop"]
          },
          {
            "heading": "ローカルLLMとAPIの選択肢",
            "body": "OpenAI以外にも、Anthropic（Claude）、Google（Gemini）、Mistral等のAPIが利用可能です。[[agent-term-local-llm|ローカルLLM]]はOllama等を使いローカル環境で動作させる選択肢で、API費用がかからず、データがローカルに留まるため機密性が高いのが利点です。ただし、モデルサイズが大きいほど高性能なGPUが必要で、クラウドAPIのモデルと比較すると性能面で劣る場合があります。エージェント開発では、計画や複雑な推論にはクラウドの高性能モデル、繰り返しの簡単なタスクにはローカルLLMという使い分けも有効です。",
            "termRefs": ["agent-term-local-llm"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-api-fundamentals", "agent-concept-function-calling", "agent-concept-langgraph-basics"]
    },
    {
      "id": "agent-topic-helpdesk",
      "term": "Helpdesk Support Agent",
      "termJa": "ヘルプデスク支援エージェント",
      "meaning": "Plan-and-Execute型エージェントで社内ヘルプデスク業務を支援する実践例。計画→ツール選択→実行→修正のサイクル。",
      "article": {
        "sections": [
          {
            "heading": "ヘルプデスク業務の課題とAIエージェントの適用",
            "body": "ヘルプデスク業務では、問い合わせに対してマニュアルや過去のQAを検索し、回答を作成する一連のフローがあります。課題として、(1)マニュアルが膨大で必要な情報を探すのに時間がかかる、(2)過去のQAが散在しており再利用が難しい、(3)回答品質が担当者のスキルに依存する、があります。[[agent-term-ai-agent|AIエージェント]]は、質問の分析→情報検索→回答生成を自律的に行い、担当者の負担を軽減します。単純なRAGと異なり、複数のサブタスクに分解して段階的に回答を組み立てる点がエージェントの強みです。",
            "termRefs": ["agent-term-ai-agent"]
          },
          {
            "heading": "Plan-and-Execute型エージェントの設計",
            "body": "[[agent-term-plan-and-execute|Plan-and-Execute型]]は、まずユーザーの質問を分析してサブタスクの計画を立て、次にサブタスクを順次実行するパターンです。計画フェーズでは「この質問に答えるには何を調べる必要があるか」を分解します。例えば「VPN接続できない場合の対処法は？」→(1)VPN設定マニュアルを検索、(2)過去の類似QAを検索、(3)情報を統合して回答を作成。実行フェーズでは、計画の各サブタスクに対してツール選択→ツール実行→サブタスク回答を繰り返します。",
            "termRefs": ["agent-term-plan-and-execute"]
          },
          {
            "heading": "検索ツールの作成とRAG",
            "body": "ヘルプデスクエージェントの中核となるのが検索ツールです。(1)マニュアル検索ツール：社内マニュアルをチャンクに分割し、[[agent-term-embedding-api|Embedding API]]でベクトル化してベクトルDBに格納。質問に意味的に近い箇所を検索する。(2)過去QA検索ツール：過去の問い合わせと回答のペアを同様にベクトル化し、類似の質問を検索する。[[agent-term-rag-long-context|RAGとロングコンテキスト]]の使い分けも重要で、マニュアル全体が[[aidev-term-context-window|コンテキストウィンドウ]]に収まるならロングコンテキスト、収まらないならRAGが適しています。単純なRAGでは「特定の情報を一箇所から取得する」質問には強いですが、「複数の条件を組み合わせる」質問には弱い点に注意が必要です。",
            "termRefs": ["agent-term-embedding-api", "agent-term-rag-long-context", "aidev-term-context-window"]
          },
          {
            "heading": "LangGraphによる実装と改善",
            "body": "[[agent-term-langgraph|LangGraph]]で計画実行型エージェントを実装する場合、主要なノードは(1)計画作成、(2)ツール選択、(3)ツール実行、(4)サブタスク回答、(5)[[agent-term-self-correction|自己修正]]、(6)最終回答です。自己修正ノードでは、回答の品質を検証し、不十分な場合は計画を修正して再実行します。正確な回答が得られない場合の原因と対策として、計画不備（質問の分解が不適切→計画プロンプトの改善）、検索精度の問題（チャンクサイズの調整、メタデータフィルタリングの追加、検索クエリの書き換え）などがあります。",
            "termRefs": ["agent-term-langgraph", "agent-term-self-correction"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-helpdesk-design", "agent-concept-search-tool-design", "agent-concept-plan-execute-impl"]
    },
    {
      "id": "agent-topic-data-analysis",
      "term": "Data Analysis Agent",
      "termJa": "データ分析エージェント",
      "meaning": "コード生成・実行・リフレクションのサイクルでデータ分析を自動化するシングルエージェントワークフロー。",
      "article": {
        "sections": [
          {
            "heading": "データ分析業務の課題とエージェントの適用",
            "body": "データ分析業務では、BIツールの操作スキルが必要、複雑な分析はSQLやPythonの知識が要求される、分析の仮説構築に時間がかかるといった課題があります。[[agent-term-ai-agent|AIエージェント]]は自然言語の指示からPythonコードを生成・実行し、結果を解釈してレポートを作成します。具体的な製品としては、OpenAIのAdvanced Data Analysis（旧Code Interpreter）、各社のBI AIアシスタントなどがあります。エージェントの設計では、[[agent-term-single-agent|シングルエージェントワークフロー]]が基本で、コード生成→実行→結果検証のサイクルを繰り返します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-single-agent"]
          },
          {
            "heading": "コード生成・実行・リフレクション",
            "body": "データ分析エージェントの中核は3つのステップのサイクルです。(1)コード生成：データの概要と分析目的をLLMに伝え、Pythonコード（pandas、matplotlib等）を生成。(2)コード実行：生成コードを[[agent-term-e2b|E2B]]等のサンドボックス環境で実行。ホストシステムへの影響を隔離しつつ、ライブラリの利用やファイル操作を可能にする。(3)[[agent-term-reflection|リフレクション]]：実行結果（出力、エラー、グラフ）をLLMに返し、コードの問題点を分析させて修正コードを生成。このサイクルを成功するまで繰り返します。[[agent-term-code-interpreter|Code Interpreter]]はこの一連のプロセスを統合的に提供する仕組みです。",
            "termRefs": ["agent-term-e2b", "agent-term-reflection", "agent-term-code-interpreter"]
          },
          {
            "heading": "分析レポートの作成",
            "body": "単発のコード実行を超えて、構造化された分析レポートを作成するには計画が必要です。(1)計画立案（仮説構築）：データの概要を分析し、「売上の季節変動パターンの特定」「顧客セグメントごとの購買傾向」等の分析仮説を生成。(2)仮説ごとのコード生成・実行：各仮説を検証するPythonコードを生成・実行し、グラフや統計結果を取得。(3)レポート生成：全ての実行結果を統合し、発見事項・考察・推奨アクションを含むMarkdownレポートを生成。この構造により、単なる集計を超えた洞察を提供できます。",
            "termRefs": ["agent-term-planning"]
          },
          {
            "heading": "課題と展望",
            "body": "データ分析エージェントの課題として、(1)データの前処理（欠損値処理、型変換）で予期しないエラーが発生しやすい、(2)生成されたグラフの解釈が浅い場合がある（相関と因果の混同等）、(3)大規模データではコード実行のリソース管理が必要。改善の方向性として、ドメイン知識をプロンプトに組み込むこと、分析パターンのテンプレート化、[[agent-term-human-in-loop|ヒューマンインザループ]]で分析の方向性を人間が確認することが有効です。将来的にはマルチモーダル（グラフの画像を直接AIが解釈）や、複数データソースを横断する分析への発展が期待されます。",
            "termRefs": ["agent-term-human-in-loop"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-code-gen-cycle", "agent-concept-analysis-report", "agent-concept-sandbox-execution"]
    }
  ],
  "concepts": [
    {
      "id": "agent-concept-agent-definition",
      "term": "Agent Definition & Characteristics",
      "termJa": "エージェントの定義と特性",
      "topicId": "agent-topic-overview",
      "meaning": "AIエージェントの定義（自律的なタスク遂行システム）と4つの特性（自律性、反応性、先見性、社会性）の理解。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-planning"]
    },
    {
      "id": "agent-concept-agent-business",
      "term": "Agent Business Applications",
      "termJa": "エージェントのビジネス活用",
      "topicId": "agent-topic-overview",
      "meaning": "カスタマーサポート、データ分析、情報収集などのビジネス活用パターンと、社内業務から顧客向けサービスへの展開戦略。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-human-in-loop"]
    },
    {
      "id": "agent-concept-llm-to-agent",
      "term": "From LLM to Agent",
      "termJa": "LLMからエージェントへの段階",
      "topicId": "agent-topic-overview",
      "meaning": "LLM単体→プロンプト設計→ツール連携→計画付き自律行動→マルチエージェントという5段階の技術発展。学習アプローチと推論アプローチの違い。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-agent-tuning"]
    },
    {
      "id": "agent-concept-framework-choice",
      "term": "Framework Selection",
      "termJa": "フレームワークの選択",
      "topicId": "agent-topic-overview",
      "meaning": "LangGraph、CrewAI、AutoGen等のエージェントフレームワークの比較と、フルスクラッチとフレームワーク利用の判断基準。",
      "relatedTermIds": ["agent-term-langgraph"]
    },
    {
      "id": "agent-concept-internal-architecture",
      "term": "Internal Architecture",
      "termJa": "内部アーキテクチャ",
      "topicId": "agent-topic-architecture",
      "meaning": "プロフィール・ツール・計画・自己修正・メモリの5要素と知覚から成るエージェントの内部構成。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-profile", "agent-term-tool-use", "agent-term-planning", "agent-term-memory"]
    },
    {
      "id": "agent-concept-profile-design",
      "term": "Profile Design",
      "termJa": "プロフィール設計",
      "topicId": "agent-topic-architecture",
      "meaning": "エージェントの役割・専門性・行動指針をシステムプロンプトとして定義する設計手法。知覚の設計を含む。",
      "relatedTermIds": ["agent-term-profile", "agent-term-perception"]
    },
    {
      "id": "agent-concept-tool-design",
      "term": "Tool Design & MCP",
      "termJa": "ツール設計とMCP",
      "topicId": "agent-topic-architecture",
      "meaning": "ツール呼び出しの実装方法、ツール説明文の設計、MCPによるツール接続の標準化。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-mcp"]
    },
    {
      "id": "agent-concept-planning-strategy",
      "term": "Planning Strategy",
      "termJa": "計画戦略",
      "topicId": "agent-topic-architecture",
      "meaning": "事前計画と動的計画の2つのアプローチ、Plan-and-Execute型の設計、再計画の仕組み。",
      "relatedTermIds": ["agent-term-planning", "agent-term-plan-and-execute"]
    },
    {
      "id": "agent-concept-self-correction-pattern",
      "term": "Self-Correction Patterns",
      "termJa": "自己修正パターン",
      "topicId": "agent-topic-architecture",
      "meaning": "出力検証、リトライ、リフレクションの3つの自己修正手法と、無限ループ防止の設計。",
      "relatedTermIds": ["agent-term-self-correction", "agent-term-reflection"]
    },
    {
      "id": "agent-concept-memory-design",
      "term": "Memory Design",
      "termJa": "メモリ設計",
      "topicId": "agent-topic-architecture",
      "meaning": "短期メモリと長期メモリの使い分け、情報の選別・保存・検索の設計、自己改善への活用。",
      "relatedTermIds": ["agent-term-memory", "agent-term-arch-self-improvement"]
    },
    {
      "id": "agent-concept-workflow-patterns",
      "term": "Workflow Patterns",
      "termJa": "ワークフローパターン",
      "topicId": "agent-topic-architecture",
      "meaning": "シングルエージェントとマルチエージェントのワークフロー設計パターン。オーケストレーター型、議論型、階層型。",
      "relatedTermIds": ["agent-term-single-agent", "agent-term-multi-agent", "agent-term-ai-workflow"]
    },
    {
      "id": "agent-concept-api-fundamentals",
      "term": "API Fundamentals",
      "termJa": "API基礎",
      "topicId": "agent-topic-dev-setup",
      "meaning": "Chat Completions API、推論モデル、構造化出力、Prompt Cachingなど、エージェント開発の基盤となるAPI知識。",
      "relatedTermIds": ["agent-term-chat-completions", "agent-term-reasoning-models", "agent-term-structured-outputs", "agent-term-prompt-caching"]
    },
    {
      "id": "agent-concept-function-calling",
      "term": "Function Calling & Tools",
      "termJa": "ツール連携の実装",
      "topicId": "agent-topic-dev-setup",
      "meaning": "Function Callingの仕組み、Web検索・RAG・Code Interpreterの実装方法、Assistants APIの活用。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-code-interpreter", "agent-term-embedding-api", "agent-term-assistants-api"]
    },
    {
      "id": "agent-concept-langgraph-basics",
      "term": "LangGraph Basics",
      "termJa": "LangGraph基礎",
      "topicId": "agent-topic-dev-setup",
      "meaning": "LangGraphのState・Node・Edge概念、ワークフローの構築手順、ヒューマンインザループの組み込み。",
      "relatedTermIds": ["agent-term-langgraph", "agent-term-human-in-loop", "agent-term-local-llm"]
    },
    {
      "id": "agent-concept-helpdesk-design",
      "term": "Helpdesk Agent Design",
      "termJa": "ヘルプデスクエージェント設計",
      "topicId": "agent-topic-helpdesk",
      "meaning": "ヘルプデスク業務の課題分析とPlan-and-Execute型エージェントの適用設計。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-plan-and-execute"]
    },
    {
      "id": "agent-concept-search-tool-design",
      "term": "Search Tool Design",
      "termJa": "検索ツール設計",
      "topicId": "agent-topic-helpdesk",
      "meaning": "マニュアル検索・過去QA検索ツールの設計、RAGとロングコンテキストの使い分け。",
      "relatedTermIds": ["agent-term-embedding-api", "agent-term-rag-long-context"]
    },
    {
      "id": "agent-concept-plan-execute-impl",
      "term": "Plan-Execute Implementation",
      "termJa": "計画実行型の実装",
      "topicId": "agent-topic-helpdesk",
      "meaning": "LangGraphによるPlan-and-Execute型エージェントの実装パターンと、計画不備・検索精度の改善手法。",
      "relatedTermIds": ["agent-term-langgraph", "agent-term-self-correction"]
    },
    {
      "id": "agent-concept-code-gen-cycle",
      "term": "Code Generation Cycle",
      "termJa": "コード生成サイクル",
      "topicId": "agent-topic-data-analysis",
      "meaning": "コード生成→サンドボックス実行→リフレクションの反復サイクル。データ分析エージェントの中核パターン。",
      "relatedTermIds": ["agent-term-reflection", "agent-term-e2b", "agent-term-code-interpreter"]
    },
    {
      "id": "agent-concept-analysis-report",
      "term": "Analysis Report Generation",
      "termJa": "分析レポート生成",
      "topicId": "agent-topic-data-analysis",
      "meaning": "仮説構築→コード実行→レポート統合の流れで構造化された分析レポートを自動生成するプロセス。",
      "relatedTermIds": ["agent-term-planning", "agent-term-single-agent"]
    },
    {
      "id": "agent-concept-sandbox-execution",
      "term": "Sandbox Execution",
      "termJa": "サンドボックス実行",
      "topicId": "agent-topic-data-analysis",
      "meaning": "E2B等の隔離環境でAI生成コードを安全に実行する仕組み。セキュリティとリソース管理。",
      "relatedTermIds": ["agent-term-e2b", "agent-term-code-interpreter"]
    }
  ],
  "terms": [
    {
      "id": "agent-term-ai-agent",
      "term": "AI Agent",
      "termJa": "AIエージェント",
      "meaning": "LLMを頭脳として、外部ツールの利用・計画の立案・自己修正を自律的に行い、与えられた目標を達成するソフトウェアシステム。単なるチャットボットと異なり、環境を認識し、判断し、行動するループを持つ。",
      "type": "theory",
      "tags": ["基礎", "全章"]
    },
    {
      "id": "agent-term-profile",
      "term": "Agent Profile",
      "termJa": "エージェントプロフィール",
      "meaning": "エージェントの役割・性格・専門領域・行動指針をシステムプロンプトとして定義したもの。プロフィール設計がエージェントの振る舞いの質を大きく左右する。",
      "type": "theory",
      "tags": ["設計", "構成要素"]
    },
    {
      "id": "agent-term-tool-use",
      "term": "Tool Use / Function Calling",
      "termJa": "ツール呼び出し",
      "meaning": "LLMが外部のAPI・データベース・検索エンジン等のツールを呼び出す機能。LLMが「どのツールを」「どの引数で」呼ぶかをJSON形式で出力し、実行結果をLLMに返すことで、LLM単体ではできない操作を実現する。",
      "type": "technique",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-planning",
      "term": "Planning",
      "termJa": "計画（プランニング）",
      "meaning": "エージェントが目標達成のために、タスクを分解し実行順序を決定するプロセス。計画の質がエージェント全体の成否を左右する。事前計画と動的再計画の2種類がある。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-self-correction",
      "term": "Self-Correction",
      "termJa": "自己修正",
      "meaning": "エージェントが自身の出力や行動の結果を評価し、誤りを検出して修正するメカニズム。リトライ、出力の再検証、代替手段への切り替えなどの戦略がある。",
      "type": "technique",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-memory",
      "term": "Agent Memory",
      "termJa": "エージェントメモリ",
      "meaning": "エージェントが過去の経験・会話履歴・学習した知識を保持する仕組み。短期メモリ（現在の会話コンテキスト）と長期メモリ（永続化された知識・経験）に分かれる。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-perception",
      "term": "Perception",
      "termJa": "知覚",
      "meaning": "エージェントが環境からの情報（ユーザー入力、ツール実行結果、外部データ）を受け取り解釈するプロセス。マルチモーダル入力（テキスト・画像・音声）の処理も含む。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-agent-tuning",
      "term": "Agent-Tuning",
      "termJa": "エージェントチューニング",
      "meaning": "LLMをエージェントタスクに特化してファインチューニングする手法。ツール呼び出しの精度向上、計画能力の強化などを目的とし、エージェント行動のトレースデータで学習する。推論時のプロンプト設計とは異なるアプローチ。",
      "type": "technique",
      "tags": ["理論", "学習"]
    },
    {
      "id": "agent-term-single-agent",
      "term": "Single-Agent Workflow",
      "termJa": "シングルエージェントワークフロー",
      "meaning": "1つのエージェントが全ての処理を担当するワークフロー。シンプルで管理しやすいが、複雑なタスクでは限界がある。コード生成→実行→リフレクションのサイクルが典型例。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-multi-agent",
      "term": "Multi-Agent Workflow",
      "termJa": "マルチエージェントワークフロー",
      "meaning": "複数の専門エージェントが協調してタスクを遂行するワークフロー。各エージェントに異なる役割を割り当て、連携させることで複雑な問題に対応する。オーケストレーター型、議論型、階層型などのパターンがある。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-chat-completions",
      "term": "Chat Completions API",
      "termJa": "チャット補完API",
      "meaning": "OpenAI等が提供する、会話形式でLLMを呼び出すAPI。system/user/assistantのロールでメッセージを送り、AIの応答を得る。エージェント開発の基盤となるインターフェース。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-reasoning-models",
      "term": "Reasoning Models",
      "termJa": "推論モデル",
      "meaning": "o1、o3等の、内部で段階的な推論プロセスを実行するLLM。通常のモデルより複雑な論理的思考が可能で、計画立案や数学的推論に優れる。エージェントの計画フェーズでの活用が期待される。",
      "type": "theory",
      "tags": ["モデル", "理論"]
    },
    {
      "id": "agent-term-structured-outputs",
      "term": "Structured Outputs",
      "termJa": "構造化出力",
      "meaning": "LLMの出力をJSONスキーマ等の事前定義された形式に強制する機能。エージェントのツール呼び出しや計画出力で、パース可能な安定した出力を保証する。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-prompt-caching",
      "term": "Prompt Caching",
      "termJa": "プロンプトキャッシング",
      "meaning": "同一のプロンプトプレフィックスを再利用し、API呼び出しのコストと遅延を削減する技術。長いシステムプロンプトや大量のコンテキストを使うエージェントで特に有効。",
      "type": "technique",
      "tags": ["開発", "最適化"]
    },
    {
      "id": "agent-term-code-interpreter",
      "term": "Code Interpreter",
      "termJa": "コードインタープリタ",
      "meaning": "AIが生成したプログラムコードをサンドボックス環境で実行し、結果を取得する仕組み。データ分析、数値計算、ファイル変換など、LLMの計算能力を補完するツールとして使われる。",
      "type": "technique",
      "tags": ["ツール", "実行環境"]
    },
    {
      "id": "agent-term-embedding-api",
      "term": "Embedding API",
      "termJa": "エンベディングAPI",
      "meaning": "テキストをベクトル（数値の配列）に変換するAPI。意味的に近いテキスト同士が近いベクトルになる性質を利用し、セマンティック検索やRAGの基盤技術として使われる。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-assistants-api",
      "term": "Assistants API",
      "termJa": "アシスタントAPI",
      "meaning": "OpenAIが提供する、ステートフルなAIアシスタントを構築するためのAPI。スレッド管理、ファイル処理、Code Interpreter、Function Callingを統合的に提供する。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-langgraph",
      "term": "LangGraph",
      "termJa": "LangGraph",
      "meaning": "LangChainチームが開発した、グラフベースのエージェントワークフロー構築フレームワーク。ステートマシンとしてエージェントの状態遷移を定義し、条件分岐・ループ・人間の介入を含む複雑なワークフローを構築できる。",
      "type": "technique",
      "tags": ["フレームワーク", "開発"]
    },
    {
      "id": "agent-term-mcp",
      "term": "Model Context Protocol (MCP)",
      "termJa": "モデルコンテキストプロトコル",
      "meaning": "Anthropicが提唱する、AIモデルと外部ツール・データソースを標準的な方法で接続するオープンプロトコル。USBのように、様々なツールをエージェントに統一的なインターフェースで接続できる。",
      "type": "technique",
      "tags": ["プロトコル", "ツール"]
    },
    {
      "id": "agent-term-plan-and-execute",
      "term": "Plan-and-Execute",
      "termJa": "計画実行型",
      "meaning": "まず全体計画を立て、その計画に基づいてサブタスクを順次実行するエージェントパターン。計画フェーズと実行フェーズを分離することで、複雑なタスクを体系的に処理する。実行結果に応じた計画の修正（再計画）も含む。",
      "type": "technique",
      "tags": ["パターン", "設計"]
    },
    {
      "id": "agent-term-reflection",
      "term": "Reflection",
      "termJa": "リフレクション",
      "meaning": "エージェントが自身の出力を振り返り、品質を評価・改善するプロセス。コード生成後にエラーを検出して修正する、回答の正確性を自己チェックするなど。自己修正の具体的な実装手法の一つ。",
      "type": "technique",
      "tags": ["パターン", "品質"]
    },
    {
      "id": "agent-term-e2b",
      "term": "E2B (Code Sandbox)",
      "termJa": "E2B（コードサンドボックス）",
      "meaning": "AIが生成したコードを安全に実行するためのクラウドサンドボックス環境。ホストシステムから隔離された環境でコードを実行し、結果を取得する。データ分析エージェントでの活用が代表的。",
      "type": "technique",
      "tags": ["ツール", "実行環境"]
    },
    {
      "id": "agent-term-langgraph-studio",
      "term": "LangGraph Studio",
      "termJa": "LangGraph Studio",
      "meaning": "LangGraphで構築したエージェントワークフローを視覚的にデバッグ・テストするためのツール。グラフの状態遷移をリアルタイムで確認でき、各ノードの入出力を検査できる。",
      "type": "technique",
      "tags": ["ツール", "デバッグ"]
    },
    {
      "id": "agent-term-local-llm",
      "term": "Local LLM",
      "termJa": "ローカルLLM",
      "meaning": "Ollama等を使いローカル環境で動作させるLLM。API費用がかからず、データがローカルに留まるため機密性が高い。ただし、モデルサイズやGPUリソースによる性能の制約がある。",
      "type": "technique",
      "tags": ["開発", "モデル"]
    },
    {
      "id": "agent-term-ai-workflow",
      "term": "AI Workflow",
      "termJa": "AIワークフロー",
      "meaning": "LLMの呼び出しとツール実行を、事前定義されたフローに基づいて制御する仕組み。エージェントほど自律的ではないが、予測可能性が高く、特定の業務プロセスの自動化に適している。エージェントの構成要素としても使われる。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-evaluation",
      "term": "Agent Evaluation",
      "termJa": "エージェント評価",
      "meaning": "AIエージェントの性能を定量的・定性的に評価するプロセス。エージェント能力（ツール使用、計画、記憶）と問題解決能力（タスクの完了度、正確性）の2軸で評価する。",
      "type": "theory",
      "tags": ["評価", "運用"]
    },
    {
      "id": "agent-term-llm-judge",
      "term": "LLM-as-a-Judge",
      "termJa": "LLMによる評価",
      "meaning": "LLM自体を評価者として使い、エージェントの出力品質を自動評価する手法。人間の評価と相関が高い場合が多く、大量のテストケースの評価を効率化できる。ただし、評価LLM自体のバイアスに注意が必要。",
      "type": "technique",
      "tags": ["評価", "手法"]
    },
    {
      "id": "agent-term-task-domain-space",
      "term": "Task Space / Domain Space",
      "termJa": "タスク空間・ドメイン空間",
      "meaning": "エージェントの評価における2つの次元。タスク空間はエージェントが解くべき問題の種類と複雑さ、ドメイン空間は業務領域固有の知識や制約を表す。評価設計時に両方をカバーすることが重要。",
      "type": "theory",
      "tags": ["評価", "理論"]
    },
    {
      "id": "agent-term-error-analysis",
      "term": "Error Analysis",
      "termJa": "エラー分析",
      "meaning": "エージェントの失敗パターンを体系的に分類・分析する手法。計画・推論エラー、行動・実行エラー、環境・知覚エラー、マルチエージェント連携エラーの4カテゴリで整理し、改善に活かす。",
      "type": "technique",
      "tags": ["評価", "改善"]
    },
    {
      "id": "agent-term-agent-ux",
      "term": "Agent UX",
      "termJa": "エージェントUX",
      "meaning": "AIエージェントとユーザーの間のインタラクション設計。エージェントの処理過程の可視化、信頼性の構築、ユーザーの承認・介入ポイントの設計など、従来のUI/UXとは異なる設計原則が求められる。",
      "type": "theory",
      "tags": ["運用", "UX"]
    },
    {
      "id": "agent-term-prompt-injection",
      "term": "Prompt Injection",
      "termJa": "プロンプトインジェクション",
      "meaning": "悪意のある入力によってエージェントの指示を上書きし、意図しない動作を引き起こす攻撃手法。間接的プロンプトインジェクション（外部データ経由）は特に防御が難しく、エージェントのセキュリティ設計で最重要課題の一つ。",
      "type": "theory",
      "tags": ["セキュリティ", "リスク"]
    },
    {
      "id": "agent-term-agentops",
      "term": "AgentOps",
      "termJa": "AgentOps",
      "meaning": "AIエージェントの運用を監視・管理するための概念・ツール群。エージェントの実行トレース、コスト追跡、パフォーマンス計測、異常検知などを包括的に行う。MLOpsのエージェント版。",
      "type": "technique",
      "tags": ["運用", "モニタリング"]
    },
    {
      "id": "agent-term-langsmith",
      "term": "LangSmith",
      "termJa": "LangSmith",
      "meaning": "LangChainチームが提供する、LLMアプリケーションの開発・テスト・モニタリングプラットフォーム。エージェントの実行トレースの可視化、プロンプトの管理、評価データセットの作成・実行が可能。",
      "type": "technique",
      "tags": ["ツール", "モニタリング"]
    },
    {
      "id": "agent-term-prompt-flow-tracing",
      "term": "Prompt Flow Tracing",
      "termJa": "Prompt Flow トレーシング",
      "meaning": "Microsoftが提供するPrompt flowのトレース機能。エージェントの各ステップ（LLM呼び出し、ツール実行、判断分岐）をDAGとして可視化し、ボトルネックの特定やデバッグに活用する。",
      "type": "technique",
      "tags": ["ツール", "モニタリング"]
    },
    {
      "id": "agent-term-human-in-loop",
      "term": "Human-in-the-Loop",
      "termJa": "ヒューマンインザループ",
      "meaning": "エージェントの処理フローに人間の判断・承認ポイントを組み込む設計パターン。重要な意思決定や不可逆な操作の前に人間の確認を挟むことで、エージェントの安全性と信頼性を確保する。",
      "type": "technique",
      "tags": ["設計", "安全性"]
    },
    {
      "id": "agent-term-guardrails",
      "term": "Guardrails",
      "termJa": "ガードレール",
      "meaning": "エージェントの行動を安全な範囲内に制限する仕組み。入力のフィルタリング、出力の検証、許可されたアクションのホワイトリスト、コスト上限の設定など、多層的な防御を構築する。",
      "type": "technique",
      "tags": ["安全性", "運用"]
    },
    {
      "id": "agent-term-arch-self-improvement",
      "term": "Agent Architecture Self-Improvement",
      "termJa": "エージェントの自己改善",
      "meaning": "エージェントが運用中の経験から学び、プロンプト・ツール選択・ワークフロー自体を改善する仕組み。メモリに蓄積された成功・失敗パターンを活用し、継続的にパフォーマンスを向上させる。",
      "type": "technique",
      "tags": ["運用", "改善"]
    },
    {
      "id": "agent-term-role-playing",
      "term": "Role-Playing Agent",
      "termJa": "ロールプレイングエージェント",
      "meaning": "特定の人物像（ペルソナ）の役割を演じるエージェント。マーケティングではターゲット顧客を模擬し、コンテンツの評価やフィードバックを行う。複数ペルソナのエージェントによるディスカッションも可能。",
      "type": "technique",
      "tags": ["パターン", "活用"]
    },
    {
      "id": "agent-term-personalization",
      "term": "Personalization Agent",
      "termJa": "パーソナライズエージェント",
      "meaning": "ユーザーの属性・行動履歴・嗜好に基づき、個別最適化された提案やコンテンツを生成するエージェント。会話を通じてユーザーの潜在ニーズを把握し、従来のルールベースを超えた柔軟なレコメンドを実現する。",
      "type": "technique",
      "tags": ["パターン", "活用"]
    },
    {
      "id": "agent-term-rag-long-context",
      "term": "RAG + Long Context",
      "termJa": "RAGとロングコンテキスト",
      "meaning": "RAG（検索拡張生成）とロングコンテキストモデルの使い分け・併用戦略。ロングコンテキストモデルは大量のテキストを直接入力できるが、コストが高い。RAGは必要な情報のみを検索するため効率的だが、検索精度に依存する。",
      "type": "technique",
      "tags": ["技術", "検索"]
    }
  ]
}
