{
  "category": "ai-agents",
  "displayName": "AIエージェント",
  "description": "AIエージェントの基礎概念から実装、評価・運用まで体系的に学ぶ。",
  "topics": [
    {
      "id": "agent-topic-overview",
      "term": "AI Agent Overview",
      "termJa": "AIエージェントの概要",
      "meaning": "AIエージェントの定義・特性、ビジネス状況、技術的な位置づけ、開発の選択肢を俯瞰する。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントとは",
            "body": "[[agent-term-ai-agent|AIエージェント]]とは、LLMを頭脳として自律的にタスクを遂行するシステムです。単なるチャットボットがユーザーの質問に1回答えるだけなのに対し、エージェントは目標に向けて複数のステップを計画し、ツールを使い、結果を検証するループを繰り返します。エージェントの特性として、(1)自律性（人間の介入なしに行動できる）、(2)反応性（環境の変化に対応する）、(3)先見性（[[agent-term-planning|計画]]を立てて行動する）、(4)社会性（他のエージェントや人間と協調する）が挙げられます。これらの特性を全て備える必要はなく、タスクに応じて必要な特性を設計に反映します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-planning"]
          },
          {
            "heading": "AIエージェントのビジネス状況と活用例",
            "body": "AIエージェントはカスタマーサポート、データ分析、情報収集、コード生成支援など、幅広い業務で活用が進んでいます。従来のRPA（ロボティック・プロセス・オートメーション）が定型作業の自動化にとどまるのに対し、AIエージェントは非定型な判断を含む業務にも対応できます。企業ではまず社内業務（ヘルプデスク、レポート作成、議事録要約）から導入し、徐々に顧客向けサービスへ展開するパターンが多く見られます。ビジネスでの活用成功の鍵は、エージェントの適用範囲を明確に限定し、[[agent-term-human-in-loop|ヒューマンインザループ]]で人間の監督を組み込むことです。",
            "termRefs": ["agent-term-human-in-loop"]
          },
          {
            "heading": "技術的な位置づけ：LLMからAIエージェントへ",
            "body": "LLMからAIエージェントまでには段階があります。(1)LLM単体：1回の入出力でテキスト生成。(2)LLM + プロンプト設計：[[aidev-term-prompt-engineering|プロンプトエンジニアリング]]で出力を制御。(3)LLM + ツール：[[agent-term-tool-use|ツール呼び出し]]で外部連携。(4)LLM + ツール + 計画：目標達成に向けた自律的な行動。(5)マルチエージェント：複数エージェントの協調。段階が上がるほど能力は増しますが、複雑性とリスクも増大します。エージェントの構築方法には「学習」と「推論」の2つのアプローチがあります。[[agent-term-agent-tuning|エージェントチューニング]]はモデル自体をエージェント行動に最適化する学習アプローチで、推論アプローチはプロンプト設計やワークフロー設計でエージェントを構築します。現在は推論アプローチが主流です。",
            "termRefs": ["aidev-term-prompt-engineering", "agent-term-tool-use", "agent-term-agent-tuning"]
          },
          {
            "heading": "AIエージェント開発の選択肢",
            "body": "エージェントの構築には、(1)フルスクラッチ開発、(2)フレームワーク利用の2つの選択肢があります。代表的なフレームワークとして[[agent-term-langgraph|LangGraph]]（LangChain系、グラフベースのワークフロー定義）、CrewAI（マルチエージェントに特化）、AutoGen（Microsoft、マルチエージェントの会話設計）、OpenAI Agents SDK（OpenAI公式）などがあります。フレームワークを使う利点は開発速度の向上とベストプラクティスの適用ですが、懸念点もあります。抽象化によりデバッグが困難になること、フレームワークの更新に追従が必要なこと、特定のユースケースへの柔軟な対応が難しい場合があることです。プロジェクトの規模・要件・チームのスキルに応じて選択しましょう。",
            "termRefs": ["agent-term-langgraph"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-agent-definition", "agent-concept-agent-business", "agent-concept-llm-to-agent", "agent-concept-framework-choice"]
    },
    {
      "id": "agent-topic-architecture",
      "term": "AI Agent Architecture",
      "termJa": "AIエージェントの構成",
      "meaning": "AIエージェントの内部構成要素（プロフィール、ツール、計画、自己修正、メモリ）とワークフローパターンを理解する。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントの内部構成",
            "body": "[[agent-term-ai-agent|AIエージェント]]の内部は、大きく分けて5つの構成要素で成り立っています。(1)[[agent-term-profile|プロフィール]]：エージェントの役割・専門性の定義。(2)[[agent-term-tool-use|ツール呼び出し]]：外部システムとのインタラクション。(3)[[agent-term-planning|計画]]：タスクの分解と実行順序の決定。(4)[[agent-term-self-correction|自己修正]]：実行結果の検証と修正。(5)[[agent-term-memory|メモリ]]：経験と知識の蓄積。これらを[[agent-term-perception|知覚]]（環境からの入力受信）が支えます。エージェントの「環境」とは、ユーザーインターフェース、利用可能なツール群、アクセス可能なデータソースなど、エージェントが相互作用する全てを指します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-profile", "agent-term-tool-use", "agent-term-planning", "agent-term-self-correction", "agent-term-memory", "agent-term-perception"]
          },
          {
            "heading": "プロフィール（Profile）",
            "body": "[[agent-term-profile|プロフィール]]はエージェントの「人格」を定義するシステムプロンプトです。役割（「あなたはヘルプデスク担当のAIです」）、専門領域、行動指針、出力形式のルールなどを含みます。実装上の注意点として、プロフィールが長すぎるとLLMの注意が分散するため、最も重要な指示を先頭に配置すること。また、禁止事項よりも推奨行動を明記する方が効果的です。[[agent-term-perception|知覚]]の設計も重要で、ユーザー入力のフォーマット変換やマルチモーダル入力（画像・音声）の処理方法をプロフィール内で定義することがあります。",
            "termRefs": ["agent-term-profile", "agent-term-perception"]
          },
          {
            "heading": "ツール呼び出しとMCP",
            "body": "[[agent-term-tool-use|ツール呼び出し]]はエージェントが外部世界に働きかける手段です。LLMが関数名と引数をJSONで出力し、ランタイムが実際の関数を実行して結果をLLMに返します。ツール設計で気を付けたいのは、(1)ツールの説明文を明確にする（LLMはこの説明でツール選択を判断する）、(2)引数の型とバリデーションを厳密にする、(3)ツール数を適度に保つ（多すぎると選択精度が下がる）ことです。[[agent-term-mcp|Model Context Protocol（MCP）]]は、ツール接続を標準化するプロトコルで、USBのように異なるツールを統一的なインターフェースで接続可能にします。MCPにより、ツールの再利用性と相互運用性が大幅に向上します。",
            "termRefs": ["agent-term-tool-use", "agent-term-mcp"]
          },
          {
            "heading": "計画（Planning）",
            "body": "[[agent-term-planning|計画]]はエージェントのタスク分解と実行戦略の決定プロセスです。計画には2つのアプローチがあります。(1)事前計画：タスク全体を最初に分解し、サブタスクのリストを生成する。(2)動的計画：1ステップずつ実行し、結果に応じて次のステップを決定する。[[agent-term-plan-and-execute|Plan-and-Execute型]]は事前計画の代表で、計画フェーズと実行フェーズを明確に分離します。実装上の注意点として、計画が粗すぎると実行時に判断が曖昧になり、細かすぎると計画自体のコストが増大します。また、計画は固定ではなく、実行結果に応じて修正（再計画）できる設計にすることが重要です。",
            "termRefs": ["agent-term-planning", "agent-term-plan-and-execute"]
          },
          {
            "heading": "自己修正（Self-Correction）",
            "body": "[[agent-term-self-correction|自己修正]]はエージェントが自身の出力を検証し、問題を修正するメカニズムです。具体的には、(1)出力の検証（生成したコードの構文チェック、回答の整合性確認）、(2)エラーのリトライ（APIエラー時の再試行、異なるアプローチでの再実行）、(3)[[agent-term-reflection|リフレクション]]（出力を振り返り品質を評価して改善する）の3つが主な手法です。実装上の注意点として、自己修正ループに上限回数を設けないと無限ループに陥るリスクがあります。また、修正の判断基準を明確にすること（何をもって「正しい」とするか）が重要です。",
            "termRefs": ["agent-term-self-correction", "agent-term-reflection"]
          },
          {
            "heading": "メモリ（Memory）",
            "body": "[[agent-term-memory|メモリ]]はエージェントが情報を保持・活用する仕組みです。(1)短期メモリ：現在の会話やタスクのコンテキスト。LLMのコンテキストウィンドウに相当し、会話が長くなると古い情報が失われる。(2)長期メモリ：永続化された知識・経験。ベクトルデータベースやファイルに保存し、必要時に検索して活用する。実装上の注意点として、短期メモリの管理では重要な情報の要約や優先度付けが必要です。長期メモリでは、保存する情報の選別基準と検索の精度が品質を左右します。メモリは[[agent-term-arch-self-improvement|エージェントの自己改善]]にも活用でき、過去の成功・失敗パターンから学習することで継続的にパフォーマンスを向上させます。",
            "termRefs": ["agent-term-memory", "agent-term-arch-self-improvement"]
          },
          {
            "heading": "ワークフロー：シングルとマルチエージェント",
            "body": "[[agent-term-single-agent|シングルエージェントワークフロー]]は1つのエージェントが全処理を担当します。コード生成→実行→検証のサイクルが典型例で、シンプルで管理しやすい反面、複雑なタスクには限界があります。実装上の注意点は、ループ回数の上限設定と、各ステップの入出力の型を明確にすることです。[[agent-term-multi-agent|マルチエージェントワークフロー]]は複数の専門エージェントが協調します。パターンとして、(1)オーケストレーター型：1つの統括エージェントが他を指揮、(2)議論型：エージェント同士が議論して合意形成、(3)階層型：上位が計画、下位が実行。実装上の注意点は、エージェント間の通信プロトコルの統一、デッドロック防止、全体の状態管理です。[[agent-term-ai-workflow|AIワークフロー]]はエージェントほど自律的ではなく、事前定義されたフローに沿って処理する仕組みで、予測可能性が高いのが特徴です。推論モデル（o1等）はエージェントの計画・推論フェーズで特に有効ですが、応答速度とコストのトレードオフを考慮する必要があります。",
            "termRefs": ["agent-term-single-agent", "agent-term-multi-agent", "agent-term-ai-workflow"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-internal-architecture", "agent-concept-profile-design", "agent-concept-tool-design", "agent-concept-planning-strategy", "agent-concept-self-correction-pattern", "agent-concept-memory-design", "agent-concept-workflow-patterns"]
    },
    {
      "id": "agent-topic-dev-setup",
      "term": "Development Setup",
      "termJa": "開発準備",
      "meaning": "AIエージェント開発に必要なAPI・ツール・フレームワークの基礎知識。Chat Completions APIからLangGraphまで。",
      "article": {
        "sections": [
          {
            "heading": "Chat Completions APIとモデルの基本",
            "body": "エージェント開発の出発点は[[agent-term-chat-completions|Chat Completions API]]です。system（システム指示）、user（ユーザー入力）、assistant（AI応答）のロールでメッセージを送り、AIの応答を得ます。代表的なモデルとして、GPT-4o（高性能・マルチモーダル）、GPT-4o-mini（高速・低コスト）などがあり、タスクの要件に応じて選択します。[[agent-term-reasoning-models|推論モデル]]（o1、o3等）は内部で段階的な推論を行い、複雑な論理的思考が可能です。エージェントの計画フェーズでの活用が期待されますが、応答速度が遅くコストも高いため、計画など高度な推論が必要な場面に限定して使うのが効果的です。",
            "termRefs": ["agent-term-chat-completions", "agent-term-reasoning-models"]
          },
          {
            "heading": "構造化出力とPrompt Caching",
            "body": "[[agent-term-structured-outputs|構造化出力]]は、LLMの出力をJSONスキーマに従った形式で強制する機能です。エージェントではツール呼び出しの引数や計画の出力で必須の機能で、パース失敗のリスクを排除します。[[agent-term-prompt-caching|プロンプトキャッシング]]は、同一のプロンプトプレフィックス（システムプロンプトや大きなコンテキスト）をキャッシュし、API呼び出しのコストと遅延を削減します。エージェントは同じシステムプロンプトで何度もAPIを呼ぶため、この最適化の効果が大きくなります。",
            "termRefs": ["agent-term-structured-outputs", "agent-term-prompt-caching"]
          },
          {
            "heading": "Function Callingとエージェント用ツール",
            "body": "[[agent-term-tool-use|Function Calling]]はLLMが外部関数を呼び出す機能で、エージェントのツール利用の基盤です。APIリクエストにツールの定義（名前・説明・引数スキーマ）を含めると、LLMは適切なタイミングでツール呼び出しをJSON形式で返します。エージェントでよく使われるツールとして、(1)Web検索：最新情報の取得、(2)RAG（非公開情報の検索）：社内ドキュメントやマニュアルの検索に[[agent-term-embedding-api|Embedding API]]でベクトル化した情報を使う、(3)[[agent-term-code-interpreter|Code Interpreter]]：生成したコードの実行。[[agent-term-assistants-api|Assistants API]]はこれらを統合的に提供するOpenAIのAPIです。",
            "termRefs": ["agent-term-tool-use", "agent-term-embedding-api", "agent-term-code-interpreter", "agent-term-assistants-api"]
          },
          {
            "heading": "LangGraphによるワークフロー構築",
            "body": "[[agent-term-langgraph|LangGraph]]はグラフベースのエージェントワークフロー構築フレームワークです。ステート（状態）を定義し、ノード（処理）とエッジ（遷移）でワークフローを構築します。条件分岐（conditional edge）により、LLMの判断結果に応じてフローを動的に切り替えられます。基本的な構築手順は、(1)State型の定義、(2)各ノード関数の実装、(3)グラフの構築（ノード追加→エッジ定義）、(4)コンパイル→実行。LangGraphの利点は、複雑なループや分岐を含むワークフローを宣言的に定義できること、状態のスナップショットによるデバッグのしやすさ、[[agent-term-human-in-loop|ヒューマンインザループ]]の組み込みが容易なことです。",
            "termRefs": ["agent-term-langgraph", "agent-term-human-in-loop"]
          },
          {
            "heading": "ローカルLLMとAPIの選択肢",
            "body": "OpenAI以外にも、Anthropic（Claude）、Google（Gemini）、Mistral等のAPIが利用可能です。[[agent-term-local-llm|ローカルLLM]]はOllama等を使いローカル環境で動作させる選択肢で、API費用がかからず、データがローカルに留まるため機密性が高いのが利点です。ただし、モデルサイズが大きいほど高性能なGPUが必要で、クラウドAPIのモデルと比較すると性能面で劣る場合があります。エージェント開発では、計画や複雑な推論にはクラウドの高性能モデル、繰り返しの簡単なタスクにはローカルLLMという使い分けも有効です。",
            "termRefs": ["agent-term-local-llm"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-api-fundamentals", "agent-concept-function-calling", "agent-concept-langgraph-basics"]
    },
    {
      "id": "agent-topic-helpdesk",
      "term": "Helpdesk Support Agent",
      "termJa": "ヘルプデスク支援エージェント",
      "meaning": "Plan-and-Execute型エージェントで社内ヘルプデスク業務を支援する実践例。計画→ツール選択→実行→修正のサイクル。",
      "article": {
        "sections": [
          {
            "heading": "ヘルプデスク業務の課題とAIエージェントの適用",
            "body": "ヘルプデスク業務では、問い合わせに対してマニュアルや過去のQAを検索し、回答を作成する一連のフローがあります。課題として、(1)マニュアルが膨大で必要な情報を探すのに時間がかかる、(2)過去のQAが散在しており再利用が難しい、(3)回答品質が担当者のスキルに依存する、があります。[[agent-term-ai-agent|AIエージェント]]は、質問の分析→情報検索→回答生成を自律的に行い、担当者の負担を軽減します。単純なRAGと異なり、複数のサブタスクに分解して段階的に回答を組み立てる点がエージェントの強みです。",
            "termRefs": ["agent-term-ai-agent"]
          },
          {
            "heading": "Plan-and-Execute型エージェントの設計",
            "body": "[[agent-term-plan-and-execute|Plan-and-Execute型]]は、まずユーザーの質問を分析してサブタスクの計画を立て、次にサブタスクを順次実行するパターンです。計画フェーズでは「この質問に答えるには何を調べる必要があるか」を分解します。例えば「VPN接続できない場合の対処法は？」→(1)VPN設定マニュアルを検索、(2)過去の類似QAを検索、(3)情報を統合して回答を作成。実行フェーズでは、計画の各サブタスクに対してツール選択→ツール実行→サブタスク回答を繰り返します。",
            "termRefs": ["agent-term-plan-and-execute"]
          },
          {
            "heading": "検索ツールの作成とRAG",
            "body": "ヘルプデスクエージェントの中核となるのが検索ツールです。(1)マニュアル検索ツール：社内マニュアルをチャンクに分割し、[[agent-term-embedding-api|Embedding API]]でベクトル化してベクトルDBに格納。質問に意味的に近い箇所を検索する。(2)過去QA検索ツール：過去の問い合わせと回答のペアを同様にベクトル化し、類似の質問を検索する。[[agent-term-rag-long-context|RAGとロングコンテキスト]]の使い分けも重要で、マニュアル全体が[[aidev-term-context-window|コンテキストウィンドウ]]に収まるならロングコンテキスト、収まらないならRAGが適しています。単純なRAGでは「特定の情報を一箇所から取得する」質問には強いですが、「複数の条件を組み合わせる」質問には弱い点に注意が必要です。",
            "termRefs": ["agent-term-embedding-api", "agent-term-rag-long-context", "aidev-term-context-window"]
          },
          {
            "heading": "LangGraphによる実装と改善",
            "body": "[[agent-term-langgraph|LangGraph]]で計画実行型エージェントを実装する場合、主要なノードは(1)計画作成、(2)ツール選択、(3)ツール実行、(4)サブタスク回答、(5)[[agent-term-self-correction|自己修正]]、(6)最終回答です。自己修正ノードでは、回答の品質を検証し、不十分な場合は計画を修正して再実行します。正確な回答が得られない場合の原因と対策として、計画不備（質問の分解が不適切→計画プロンプトの改善）、検索精度の問題（チャンクサイズの調整、メタデータフィルタリングの追加、検索クエリの書き換え）などがあります。",
            "termRefs": ["agent-term-langgraph", "agent-term-self-correction"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-helpdesk-design", "agent-concept-search-tool-design", "agent-concept-plan-execute-impl"]
    },
    {
      "id": "agent-topic-data-analysis",
      "term": "Data Analysis Agent",
      "termJa": "データ分析エージェント",
      "meaning": "コード生成・実行・リフレクションのサイクルでデータ分析を自動化するシングルエージェントワークフロー。",
      "article": {
        "sections": [
          {
            "heading": "データ分析業務の課題とエージェントの適用",
            "body": "データ分析業務では、BIツールの操作スキルが必要、複雑な分析はSQLやPythonの知識が要求される、分析の仮説構築に時間がかかるといった課題があります。[[agent-term-ai-agent|AIエージェント]]は自然言語の指示からPythonコードを生成・実行し、結果を解釈してレポートを作成します。具体的な製品としては、OpenAIのAdvanced Data Analysis（旧Code Interpreter）、各社のBI AIアシスタントなどがあります。エージェントの設計では、[[agent-term-single-agent|シングルエージェントワークフロー]]が基本で、コード生成→実行→結果検証のサイクルを繰り返します。",
            "termRefs": ["agent-term-ai-agent", "agent-term-single-agent"]
          },
          {
            "heading": "コード生成・実行・リフレクション",
            "body": "データ分析エージェントの中核は3つのステップのサイクルです。(1)コード生成：データの概要と分析目的をLLMに伝え、Pythonコード（pandas、matplotlib等）を生成。(2)コード実行：生成コードを[[agent-term-e2b|E2B]]等のサンドボックス環境で実行。ホストシステムへの影響を隔離しつつ、ライブラリの利用やファイル操作を可能にする。(3)[[agent-term-reflection|リフレクション]]：実行結果（出力、エラー、グラフ）をLLMに返し、コードの問題点を分析させて修正コードを生成。このサイクルを成功するまで繰り返します。[[agent-term-code-interpreter|Code Interpreter]]はこの一連のプロセスを統合的に提供する仕組みです。",
            "termRefs": ["agent-term-e2b", "agent-term-reflection", "agent-term-code-interpreter"]
          },
          {
            "heading": "分析レポートの作成",
            "body": "単発のコード実行を超えて、構造化された分析レポートを作成するには計画が必要です。(1)計画立案（仮説構築）：データの概要を分析し、「売上の季節変動パターンの特定」「顧客セグメントごとの購買傾向」等の分析仮説を生成。(2)仮説ごとのコード生成・実行：各仮説を検証するPythonコードを生成・実行し、グラフや統計結果を取得。(3)レポート生成：全ての実行結果を統合し、発見事項・考察・推奨アクションを含むMarkdownレポートを生成。この構造により、単なる集計を超えた洞察を提供できます。",
            "termRefs": ["agent-term-planning"]
          },
          {
            "heading": "課題と展望",
            "body": "データ分析エージェントの課題として、(1)データの前処理（欠損値処理、型変換）で予期しないエラーが発生しやすい、(2)生成されたグラフの解釈が浅い場合がある（相関と因果の混同等）、(3)大規模データではコード実行のリソース管理が必要。改善の方向性として、ドメイン知識をプロンプトに組み込むこと、分析パターンのテンプレート化、[[agent-term-human-in-loop|ヒューマンインザループ]]で分析の方向性を人間が確認することが有効です。将来的にはマルチモーダル（グラフの画像を直接AIが解釈）や、複数データソースを横断する分析への発展が期待されます。",
            "termRefs": ["agent-term-human-in-loop"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-code-gen-cycle", "agent-concept-analysis-report", "agent-concept-sandbox-execution"]
    },
    {
      "id": "agent-topic-research",
      "term": "Research Agent",
      "termJa": "情報収集エージェント",
      "meaning": "arXiv論文探索を例に、マルチエージェントによる情報収集の自動化を学ぶ。メイン・調査・分析の3エージェント構成。",
      "article": {
        "sections": [
          {
            "heading": "情報収集タスクの課題",
            "body": "リサーチ業務では、(1)調査対象の事前知識がないことが多い、(2)関連情報が広範囲に散在する、(3)情報の関連性の判断に専門知識が必要、という課題があります。エージェントによるアプローチでは、「キーワードの探索→情報の収集→内容の分析→追加調査の判断」という探索プロセスを自動化します。情報収集は1つのエージェントでは難しく、調査と分析を別の専門エージェントに分担させる[[agent-term-multi-agent|マルチエージェントワークフロー]]が有効です。",
            "termRefs": ["agent-term-multi-agent"]
          },
          {
            "heading": "マルチエージェント設計",
            "body": "arXiv探索エージェントは3つのエージェントで構成されます。(1)メインエージェント（ResearchAgent）：全体の調査戦略を立て、調査・分析エージェントに指示を出し、最終レポートを統合するオーケストレーター。(2)論文調査エージェント（PaperSearchAgent）：arXiv APIやセマンティック検索で関連論文を探索。検索クエリの生成、結果のフィルタリング、重要度の判定を担当。(3)論文分析エージェント（PaperAnalyzerAgent）：取得した論文の要約、手法の分析、他の論文との比較を担当。各エージェントは[[agent-term-langgraph|LangGraph]]のサブグラフとして実装し、メインエージェントのグラフに組み込みます。",
            "termRefs": ["agent-term-langgraph"]
          },
          {
            "heading": "LangGraph Studioによる動作確認",
            "body": "[[agent-term-langgraph-studio|LangGraph Studio]]を使うと、エージェントワークフローの動作を視覚的にデバッグできます。langgraph.jsonで設定を定義し、Studioを起動すると、グラフの各ノードの実行状態、入出力データ、状態遷移をリアルタイムで確認できます。特にマルチエージェントでは、どのエージェントがどの順序で呼ばれたか、エージェント間でどのような情報が渡されたかを追跡するのに非常に有用です。開発中のデバッグだけでなく、プロダクション環境でのトレース分析にも活用できます。",
            "termRefs": ["agent-term-langgraph-studio"]
          },
          {
            "heading": "課題と今後の発展性",
            "body": "情報収集エージェントの課題として、(1)文献調査の「深さ」の限界：エージェントは幅広い探索は得意だが、特定トピックの深掘りは人間の専門知識が必要、(2)論文内の実験結果や図表の解釈が困難、(3)検索クエリの生成精度が結果の質を大きく左右する。改善の方向性として、ドメイン知識のプロフィールへの組み込み、マルチモーダル対応（図表の解析）、[[agent-term-memory|メモリ]]を活用した過去の調査結果の蓄積・再利用、ユーザーとの対話を通じた調査方針の動的調整（[[agent-term-human-in-loop|ヒューマンインザループ]]）が挙げられます。",
            "termRefs": ["agent-term-memory", "agent-term-human-in-loop"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-research-multi-agent", "agent-concept-langgraph-debug"]
    },
    {
      "id": "agent-topic-marketing",
      "term": "Marketing Support Agent",
      "termJa": "マーケティング支援エージェント",
      "meaning": "ロールプレイングによる意思決定支援とパーソナライズ施策支援の2つのマルチエージェントパターンを学ぶ。",
      "article": {
        "sections": [
          {
            "heading": "マーケティング業務とAIエージェント",
            "body": "マーケティング業務は、顧客の購買意思決定プロセス（認知→興味→検討→購入→推奨）の各段階に対してアプローチを設計します。課題として、(1)ターゲット顧客の反応予測が困難、(2)パーソナライズの精度とスケールの両立が難しい、(3)施策の効果検証に時間がかかる、があります。[[agent-term-ai-agent|AIエージェント]]は、ターゲット顧客のシミュレーション、コンテンツの最適化、個別レコメンドなどで活用できます。特に[[agent-term-multi-agent|マルチエージェント]]構成により、異なる視点からの分析や複数ペルソナのシミュレーションが可能になります。",
            "termRefs": ["agent-term-ai-agent", "agent-term-multi-agent"]
          },
          {
            "heading": "ロールプレイングによる意思決定支援",
            "body": "[[agent-term-role-playing|ロールプレイングエージェント]]は、ターゲット顧客のペルソナを演じ、マーケティングコンテンツの評価やフィードバックを行います。マルチエージェント構成では、(1)コンテンツ作成エージェント：広告文やキャッチコピーを生成、(2)ペルソナエージェント（複数）：20代女性、40代ビジネスマン等の異なるペルソナでコンテンツを評価、(3)改善提案エージェント：ペルソナの評価を統合し、改善案を生成。この構成により、従来はフォーカスグループインタビュー等で時間をかけて行っていたコンテンツ評価を高速に回せます。ただし、AIペルソナの反応は実際の消費者と異なる場合があるため、最終判断は人間が行うべきです。",
            "termRefs": ["agent-term-role-playing"]
          },
          {
            "heading": "パーソナライズ施策支援",
            "body": "[[agent-term-personalization|パーソナライズエージェント]]は、会話を通じてユーザーの嗜好を把握し、個別最適化されたレコメンドを提供します。従来のルールベース・協調フィルタリングと異なり、AIエージェントは「なぜこれを勧めるのか」を自然言語で説明でき、ユーザーとの対話を通じてリアルタイムに提案を調整できます。マルチエージェント構成では、(1)会話エージェント：ユーザーとの対話を管理、(2)プロファイル分析エージェント：対話から嗜好を抽出・構造化、(3)レコメンドエージェント：プロファイルと商品データに基づいて提案を生成。エージェントの[[agent-term-memory|メモリ]]に過去の対話や購買履歴を蓄積することで、セッションをまたいだ継続的なパーソナライズが実現します。",
            "termRefs": ["agent-term-personalization", "agent-term-memory"]
          },
          {
            "heading": "マルチエージェント連携のポイント",
            "body": "マーケティング向けマルチエージェントの設計で重要なのは、(1)各エージェントの役割を明確に分離する：ペルソナエージェントはコンテンツ作成に関与しない、レコメンドエージェントはプロファイル分析に関与しない、(2)エージェント間の情報伝達を構造化する：[[agent-term-structured-outputs|構造化出力]]で評価結果やプロファイルを定型フォーマットにする、(3)全体のオーケストレーションを設計する：どのエージェントをどの順序で呼ぶか、結果をどう統合するか。[[agent-term-langgraph|LangGraph]]のサブグラフ機能を活用し、各エージェントを独立したグラフとして実装・テストし、メインのワークフローに組み込む方法が効果的です。",
            "termRefs": ["agent-term-structured-outputs", "agent-term-langgraph"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-role-playing-design", "agent-concept-personalization-design"]
    },
    {
      "id": "agent-topic-evaluation",
      "term": "Agent Evaluation",
      "termJa": "AIエージェントの評価",
      "meaning": "エージェントの能力と問題解決力を定量的に評価する手法。評価指標、LLM-as-a-Judge、エラー分析パターンを理解する。",
      "article": {
        "sections": [
          {
            "heading": "エージェント評価の2つの軸",
            "body": "[[agent-term-evaluation|エージェント評価]]は2つの軸で考えます。(1)エージェント能力の評価：ツール使用の正確性、計画の適切さ、自己修正の有効性、メモリの活用度など、エージェントの構成要素ごとの性能を測る。(2)問題解決能力の評価：最終的なタスク達成度を測る。正答率、完了率、ユーザー満足度など。[[agent-term-task-domain-space|タスク空間とドメイン空間]]の概念も重要で、タスク空間は「何をさせるか」の多様性（簡単な質問→複雑な多段階タスク）、ドメイン空間は「どの業務領域か」の範囲（IT、法務、医療等）を表します。評価はこの2次元をバランスよくカバーする必要があります。",
            "termRefs": ["agent-term-evaluation", "agent-term-task-domain-space"]
          },
          {
            "heading": "評価指標",
            "body": "エージェント能力の指標として、(1)ツール選択の正確性（正しいツールを正しい引数で呼べたか）、(2)計画の妥当性（サブタスクの分解が適切か）、(3)自己修正の成功率（エラーから回復できたか）。問題解決能力の指標として、(1)タスク完了率、(2)回答の正確性・完全性、(3)ユーザー満足度。運用指標として、(1)レイテンシ（応答時間）、(2)コスト（API呼び出し回数・トークン数）、(3)安全性（不適切な回答の発生率）。これらの指標を組み合わせて、エージェントの総合的な品質を評価します。",
            "termRefs": ["agent-term-evaluation"]
          },
          {
            "heading": "LLM-as-a-Judgeと評価の準備",
            "body": "[[agent-term-llm-judge|LLM-as-a-Judge]]は、LLM自体を評価者として使い、エージェントの出力品質を自動評価する手法です。評価プロンプトに評価基準と被評価テキストを入力し、スコアや判定を出力させます。人間の評価と相関が高い場合が多く、大量のテストケースの評価を効率化できます。ただし、(1)評価LLM自体のバイアス（自分が生成した回答を高く評価しがち）、(2)評価基準の曖昧さ、(3)文化的・言語的な偏り、に注意が必要です。評価の準備として、代表的なテストケースの作成、期待出力（ゴールドスタンダード）の定義、評価プロンプトの設計とキャリブレーションを行います。",
            "termRefs": ["agent-term-llm-judge"]
          },
          {
            "heading": "エラー分析パターン",
            "body": "[[agent-term-error-analysis|エラー分析]]はエージェントの失敗を体系的に分類し、改善に活かす手法です。(1)計画・推論エラー：タスクの分解が不適切、サブタスクの順序が誤り、不要なステップの追加。(2)行動・実行エラー：誤ったツールの選択、引数の誤り、APIエラーのハンドリング失敗。(3)環境・知覚エラー：ツール実行結果の誤解釈、ユーザー意図の取り違え、コンテキストの見落とし。(4)マルチエージェントエラー：エージェント間の情報伝達の齟齬、責任範囲の重複・隙間、デッドロック。各カテゴリの頻度と影響度を分析し、最も効果的な改善箇所を特定します。",
            "termRefs": ["agent-term-error-analysis"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-evaluation-axes", "agent-concept-llm-judge", "agent-concept-error-patterns"]
    },
    {
      "id": "agent-topic-production",
      "term": "Agent in Production",
      "termJa": "AIエージェントの活用",
      "meaning": "エージェントのUX設計、リスク管理、モニタリング、継続的改善など、本番運用に必要な知識。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントとUX設計",
            "body": "[[agent-term-agent-ux|エージェントUX]]は従来のUI/UXとは異なる設計原則が必要です。エージェントの実利用に至るまでのステップとして、(1)ユーザーがエージェントの能力範囲を理解する、(2)信頼関係を構築する（最初は簡単なタスクから）、(3)徐々に複雑なタスクを委任する。ユーザーとのタッチポイントの設計も重要で、(1)タスク投入時：何をしてほしいかの明確な入力手段、(2)処理中：何をしているかの可視化（進捗表示、使用ツールの表示）、(3)確認ポイント：重要な判断で[[agent-term-human-in-loop|ヒューマンインザループ]]の介入、(4)結果提示：根拠とともに結果を提示。エージェントの信頼性を高めるために、「わからないことはわからないと言う」「推測する場合はその旨を明示する」という透明性が重要です。",
            "termRefs": ["agent-term-agent-ux", "agent-term-human-in-loop"]
          },
          {
            "heading": "リスクと安全性",
            "body": "エージェントのリスクは、(1)不正確な出力（[[aidev-term-hallucination|ハルシネーション]]による誤った回答や行動）、(2)セキュリティリスク（[[agent-term-prompt-injection|プロンプトインジェクション]]による指示の乗っ取り）、(3)過剰な行動（許可範囲を超えた操作）、(4)情報漏洩（機密データの不適切な利用）。攻撃手法として、直接的プロンプトインジェクション（ユーザー入力での攻撃）と間接的プロンプトインジェクション（外部データに仕込まれた攻撃）があります。対策として[[agent-term-guardrails|ガードレール]]の実装が不可欠です。入力のサニタイズ、出力のバリデーション、アクションのホワイトリスト、コスト上限の設定、人間の承認フローを多層的に組み合わせます。",
            "termRefs": ["aidev-term-hallucination", "agent-term-prompt-injection", "agent-term-guardrails"]
          },
          {
            "heading": "モニタリングツール",
            "body": "エージェントの運用には継続的なモニタリングが不可欠です。(1)[[agent-term-agentops|AgentOps]]：エージェント専用のモニタリングプラットフォーム。実行トレース、コスト追跡、パフォーマンス計測を統合的に提供。(2)[[agent-term-prompt-flow-tracing|Prompt Flow Tracing]]：Microsoftが提供するトレーシングツール。エージェントの各ステップをDAGとして可視化し、ボトルネックの特定に活用。(3)[[agent-term-langsmith|LangSmith]]：LangChainエコシステムのモニタリング。実行トレースの保存・検索、評価データセットの管理、プロンプトのバージョン管理が可能。これらのツールで、レイテンシ異常、エラー率上昇、コスト急増などを早期に検出し、対応できます。",
            "termRefs": ["agent-term-agentops", "agent-term-prompt-flow-tracing", "agent-term-langsmith"]
          },
          {
            "heading": "継続的な精度改善",
            "body": "エージェントの品質は、デプロイ後も継続的に改善する必要があります。[[agent-term-arch-self-improvement|エージェントの自己改善]]のアプローチとして、(1)[[agent-term-memory|メモリ]]を活用した推論の改善：過去の成功・失敗パターンをメモリに蓄積し、類似のタスクで参照する。(2)ツールやプロンプトの改善：モニタリングデータから頻出のエラーパターンを特定し、ツールの説明文やプロンプトを調整する。(3)エージェントアーキテクチャの改善：ワークフローの構造自体を見直す（ノードの追加・削除・順序変更）。改善サイクルの確立には、[[agent-term-evaluation|評価]]→分析→改善→再評価のループを継続的に回す体制が必要です。",
            "termRefs": ["agent-term-arch-self-improvement", "agent-term-memory", "agent-term-evaluation"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-ux-design", "agent-concept-security", "agent-concept-monitoring", "agent-concept-continuous-improvement"]
    },
    {
      "id": "agent-topic-case-studies",
      "term": "Case Studies",
      "termJa": "実用化の取り組み",
      "meaning": "AIエージェントの実プロジェクトでの進め方、開発手法、人間との協働の在り方を各社の事例から学ぶ。",
      "article": {
        "sections": [
          {
            "heading": "AIエージェントプロジェクトの進め方",
            "body": "AIエージェントの開発プロジェクトでは、(1)適用業務の選定：エージェントに適した業務の見極めが最重要。反復的でルールがある程度明確、かつ判断を伴う業務が向いている。完全に定型的な作業はRPAの方が適切で、極めて高度な判断が必要な業務はまだAIには難しい。(2)プロトタイプの早期検証：最小限のツールと簡単なワークフローでPoC（概念実証）を作成し、エージェントで解決可能かを確認する。(3)段階的な拡張：ツールの追加、ワークフローの複雑化、対応範囲の拡大を段階的に行う。(4)評価基準の事前定義：「何をもって成功とするか」をプロジェクト開始時に定義する。",
            "termRefs": ["agent-term-ai-agent"]
          },
          {
            "heading": "AIエージェントの開発手法",
            "body": "実務でのエージェント開発では、(1)最小限のワークフローから始める：最初から複雑なマルチエージェントを組まず、[[agent-term-single-agent|シングルエージェント]]で基本機能を検証。(2)ツールを段階的に追加する：各ツールが正しく動作することを個別にテストしてから組み込む。(3)[[agent-term-evaluation|評価]]を自動化する：テストケースとLLM-as-a-Judgeを組み合わせ、変更のたびに品質を検証。(4)[[agent-term-guardrails|ガードレール]]を最初から組み込む：安全装置は後付けではなく設計時から考慮する。(5)ログとトレースを充実させる：[[agent-term-agentops|AgentOps]]等のモニタリングを初期から導入し、問題の早期発見を可能にする。",
            "termRefs": ["agent-term-single-agent", "agent-term-evaluation", "agent-term-guardrails", "agent-term-agentops"]
          },
          {
            "heading": "AIエージェントと人間の協働",
            "body": "AIエージェントの実用化において最も重要なのは、エージェントと人間の適切な役割分担です。エージェントが得意なこと：大量の情報処理、定型的な判断、24時間稼働、一貫性のある対応。人間が得意なこと：文脈の深い理解、倫理的判断、創造的な問題解決、例外的な状況への対応。[[agent-term-human-in-loop|ヒューマンインザループ]]の設計では、エージェントの自信度に応じて人間への確認頻度を調整するアプローチが有効です。また、エージェントの判断を人間が監督する「人間によるレビュー」と、エージェントが人間の作業を支援する「AIアシスタント」の2つのモデルを業務に応じて使い分けることが重要です。",
            "termRefs": ["agent-term-human-in-loop"]
          }
        ]
      },
      "relatedConceptIds": ["agent-concept-project-approach", "agent-concept-human-collaboration"]
    }
  ],
  "concepts": [
    {
      "id": "agent-concept-agent-definition",
      "term": "Agent Definition & Characteristics",
      "termJa": "エージェントの定義と特性",
      "topicId": "agent-topic-overview",
      "meaning": "AIエージェントの定義（自律的なタスク遂行システム）と4つの特性（自律性、反応性、先見性、社会性）の理解。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-planning"]
    },
    {
      "id": "agent-concept-agent-business",
      "term": "Agent Business Applications",
      "termJa": "エージェントのビジネス活用",
      "topicId": "agent-topic-overview",
      "meaning": "カスタマーサポート、データ分析、情報収集などのビジネス活用パターンと、社内業務から顧客向けサービスへの展開戦略。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-human-in-loop"]
    },
    {
      "id": "agent-concept-llm-to-agent",
      "term": "From LLM to Agent",
      "termJa": "LLMからエージェントへの段階",
      "topicId": "agent-topic-overview",
      "meaning": "LLM単体→プロンプト設計→ツール連携→計画付き自律行動→マルチエージェントという5段階の技術発展。学習アプローチと推論アプローチの違い。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-agent-tuning"]
    },
    {
      "id": "agent-concept-framework-choice",
      "term": "Framework Selection",
      "termJa": "フレームワークの選択",
      "topicId": "agent-topic-overview",
      "meaning": "LangGraph、CrewAI、AutoGen等のエージェントフレームワークの比較と、フルスクラッチとフレームワーク利用の判断基準。",
      "relatedTermIds": ["agent-term-langgraph"]
    },
    {
      "id": "agent-concept-internal-architecture",
      "term": "Internal Architecture",
      "termJa": "内部アーキテクチャ",
      "topicId": "agent-topic-architecture",
      "meaning": "プロフィール・ツール・計画・自己修正・メモリの5要素と知覚から成るエージェントの内部構成。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-profile", "agent-term-tool-use", "agent-term-planning", "agent-term-memory"]
    },
    {
      "id": "agent-concept-profile-design",
      "term": "Profile Design",
      "termJa": "プロフィール設計",
      "topicId": "agent-topic-architecture",
      "meaning": "エージェントの役割・専門性・行動指針をシステムプロンプトとして定義する設計手法。知覚の設計を含む。",
      "relatedTermIds": ["agent-term-profile", "agent-term-perception"]
    },
    {
      "id": "agent-concept-tool-design",
      "term": "Tool Design & MCP",
      "termJa": "ツール設計とMCP",
      "topicId": "agent-topic-architecture",
      "meaning": "ツール呼び出しの実装方法、ツール説明文の設計、MCPによるツール接続の標準化。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-mcp"]
    },
    {
      "id": "agent-concept-planning-strategy",
      "term": "Planning Strategy",
      "termJa": "計画戦略",
      "topicId": "agent-topic-architecture",
      "meaning": "事前計画と動的計画の2つのアプローチ、Plan-and-Execute型の設計、再計画の仕組み。",
      "relatedTermIds": ["agent-term-planning", "agent-term-plan-and-execute"]
    },
    {
      "id": "agent-concept-self-correction-pattern",
      "term": "Self-Correction Patterns",
      "termJa": "自己修正パターン",
      "topicId": "agent-topic-architecture",
      "meaning": "出力検証、リトライ、リフレクションの3つの自己修正手法と、無限ループ防止の設計。",
      "relatedTermIds": ["agent-term-self-correction", "agent-term-reflection"]
    },
    {
      "id": "agent-concept-memory-design",
      "term": "Memory Design",
      "termJa": "メモリ設計",
      "topicId": "agent-topic-architecture",
      "meaning": "短期メモリと長期メモリの使い分け、情報の選別・保存・検索の設計、自己改善への活用。",
      "relatedTermIds": ["agent-term-memory", "agent-term-arch-self-improvement"]
    },
    {
      "id": "agent-concept-workflow-patterns",
      "term": "Workflow Patterns",
      "termJa": "ワークフローパターン",
      "topicId": "agent-topic-architecture",
      "meaning": "シングルエージェントとマルチエージェントのワークフロー設計パターン。オーケストレーター型、議論型、階層型。",
      "relatedTermIds": ["agent-term-single-agent", "agent-term-multi-agent", "agent-term-ai-workflow"]
    },
    {
      "id": "agent-concept-api-fundamentals",
      "term": "API Fundamentals",
      "termJa": "API基礎",
      "topicId": "agent-topic-dev-setup",
      "meaning": "Chat Completions API、推論モデル、構造化出力、Prompt Cachingなど、エージェント開発の基盤となるAPI知識。",
      "relatedTermIds": ["agent-term-chat-completions", "agent-term-reasoning-models", "agent-term-structured-outputs", "agent-term-prompt-caching"]
    },
    {
      "id": "agent-concept-function-calling",
      "term": "Function Calling & Tools",
      "termJa": "ツール連携の実装",
      "topicId": "agent-topic-dev-setup",
      "meaning": "Function Callingの仕組み、Web検索・RAG・Code Interpreterの実装方法、Assistants APIの活用。",
      "relatedTermIds": ["agent-term-tool-use", "agent-term-code-interpreter", "agent-term-embedding-api", "agent-term-assistants-api"]
    },
    {
      "id": "agent-concept-langgraph-basics",
      "term": "LangGraph Basics",
      "termJa": "LangGraph基礎",
      "topicId": "agent-topic-dev-setup",
      "meaning": "LangGraphのState・Node・Edge概念、ワークフローの構築手順、ヒューマンインザループの組み込み。",
      "relatedTermIds": ["agent-term-langgraph", "agent-term-human-in-loop", "agent-term-local-llm"]
    },
    {
      "id": "agent-concept-helpdesk-design",
      "term": "Helpdesk Agent Design",
      "termJa": "ヘルプデスクエージェント設計",
      "topicId": "agent-topic-helpdesk",
      "meaning": "ヘルプデスク業務の課題分析とPlan-and-Execute型エージェントの適用設計。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-plan-and-execute"]
    },
    {
      "id": "agent-concept-search-tool-design",
      "term": "Search Tool Design",
      "termJa": "検索ツール設計",
      "topicId": "agent-topic-helpdesk",
      "meaning": "マニュアル検索・過去QA検索ツールの設計、RAGとロングコンテキストの使い分け。",
      "relatedTermIds": ["agent-term-embedding-api", "agent-term-rag-long-context"]
    },
    {
      "id": "agent-concept-plan-execute-impl",
      "term": "Plan-Execute Implementation",
      "termJa": "計画実行型の実装",
      "topicId": "agent-topic-helpdesk",
      "meaning": "LangGraphによるPlan-and-Execute型エージェントの実装パターンと、計画不備・検索精度の改善手法。",
      "relatedTermIds": ["agent-term-langgraph", "agent-term-self-correction"]
    },
    {
      "id": "agent-concept-code-gen-cycle",
      "term": "Code Generation Cycle",
      "termJa": "コード生成サイクル",
      "topicId": "agent-topic-data-analysis",
      "meaning": "コード生成→サンドボックス実行→リフレクションの反復サイクル。データ分析エージェントの中核パターン。",
      "relatedTermIds": ["agent-term-reflection", "agent-term-e2b", "agent-term-code-interpreter"]
    },
    {
      "id": "agent-concept-analysis-report",
      "term": "Analysis Report Generation",
      "termJa": "分析レポート生成",
      "topicId": "agent-topic-data-analysis",
      "meaning": "仮説構築→コード実行→レポート統合の流れで構造化された分析レポートを自動生成するプロセス。",
      "relatedTermIds": ["agent-term-planning", "agent-term-single-agent"]
    },
    {
      "id": "agent-concept-sandbox-execution",
      "term": "Sandbox Execution",
      "termJa": "サンドボックス実行",
      "topicId": "agent-topic-data-analysis",
      "meaning": "E2B等の隔離環境でAI生成コードを安全に実行する仕組み。セキュリティとリソース管理。",
      "relatedTermIds": ["agent-term-e2b", "agent-term-code-interpreter"]
    },
    {
      "id": "agent-concept-research-multi-agent",
      "term": "Research Multi-Agent Design",
      "termJa": "調査マルチエージェント設計",
      "topicId": "agent-topic-research",
      "meaning": "メイン・調査・分析の3エージェント構成による情報収集の自動化。各エージェントの役割分担とオーケストレーション。",
      "relatedTermIds": ["agent-term-multi-agent", "agent-term-langgraph"]
    },
    {
      "id": "agent-concept-langgraph-debug",
      "term": "LangGraph Debugging",
      "termJa": "LangGraphデバッグ",
      "topicId": "agent-topic-research",
      "meaning": "LangGraph Studioを使ったワークフローの視覚的デバッグ。ノード実行状態、状態遷移、データフローの確認。",
      "relatedTermIds": ["agent-term-langgraph-studio", "agent-term-langgraph"]
    },
    {
      "id": "agent-concept-role-playing-design",
      "term": "Role-Playing Agent Design",
      "termJa": "ロールプレイング設計",
      "topicId": "agent-topic-marketing",
      "meaning": "ペルソナエージェントによるコンテンツ評価・フィードバック。複数ペルソナの議論によるマルチ視点分析。",
      "relatedTermIds": ["agent-term-role-playing", "agent-term-multi-agent"]
    },
    {
      "id": "agent-concept-personalization-design",
      "term": "Personalization Agent Design",
      "termJa": "パーソナライズエージェント設計",
      "topicId": "agent-topic-marketing",
      "meaning": "会話型レコメンドのマルチエージェント設計。プロファイル分析、レコメンド生成、メモリによる継続的パーソナライズ。",
      "relatedTermIds": ["agent-term-personalization", "agent-term-memory"]
    },
    {
      "id": "agent-concept-evaluation-axes",
      "term": "Evaluation Axes",
      "termJa": "評価の2軸",
      "topicId": "agent-topic-evaluation",
      "meaning": "エージェント能力評価と問題解決能力評価の2軸。タスク空間とドメイン空間の概念。",
      "relatedTermIds": ["agent-term-evaluation", "agent-term-task-domain-space"]
    },
    {
      "id": "agent-concept-llm-judge",
      "term": "LLM-as-a-Judge Methodology",
      "termJa": "LLM評価手法",
      "topicId": "agent-topic-evaluation",
      "meaning": "LLMを評価者として活用する手法。評価プロンプトの設計、バイアスへの対処、テストケースの準備。",
      "relatedTermIds": ["agent-term-llm-judge"]
    },
    {
      "id": "agent-concept-error-patterns",
      "term": "Error Analysis Patterns",
      "termJa": "エラー分析パターン",
      "topicId": "agent-topic-evaluation",
      "meaning": "計画・推論、行動・実行、環境・知覚、マルチエージェントの4カテゴリのエラーパターンの分類と対策。",
      "relatedTermIds": ["agent-term-error-analysis"]
    },
    {
      "id": "agent-concept-ux-design",
      "term": "Agent UX Design",
      "termJa": "エージェントUX設計",
      "topicId": "agent-topic-production",
      "meaning": "エージェントとユーザーのタッチポイント設計、信頼構築、透明性の確保。",
      "relatedTermIds": ["agent-term-agent-ux", "agent-term-human-in-loop"]
    },
    {
      "id": "agent-concept-security",
      "term": "Agent Security",
      "termJa": "エージェントセキュリティ",
      "topicId": "agent-topic-production",
      "meaning": "プロンプトインジェクション対策、ガードレールの多層実装、アクション制限の設計。",
      "relatedTermIds": ["agent-term-prompt-injection", "agent-term-guardrails"]
    },
    {
      "id": "agent-concept-monitoring",
      "term": "Agent Monitoring",
      "termJa": "エージェントモニタリング",
      "topicId": "agent-topic-production",
      "meaning": "AgentOps、LangSmith、Prompt Flow Tracingなどのモニタリングツールの活用とトレース分析。",
      "relatedTermIds": ["agent-term-agentops", "agent-term-langsmith", "agent-term-prompt-flow-tracing"]
    },
    {
      "id": "agent-concept-continuous-improvement",
      "term": "Continuous Improvement",
      "termJa": "継続的改善",
      "topicId": "agent-topic-production",
      "meaning": "メモリ活用、プロンプト最適化、アーキテクチャ改善の3つの改善アプローチと評価サイクルの確立。",
      "relatedTermIds": ["agent-term-arch-self-improvement", "agent-term-memory", "agent-term-evaluation"]
    },
    {
      "id": "agent-concept-project-approach",
      "term": "Project Approach",
      "termJa": "プロジェクトの進め方",
      "topicId": "agent-topic-case-studies",
      "meaning": "適用業務の選定、プロトタイプ検証、段階的拡張、評価基準の事前定義など実プロジェクトの進め方。",
      "relatedTermIds": ["agent-term-ai-agent", "agent-term-evaluation"]
    },
    {
      "id": "agent-concept-human-collaboration",
      "term": "Human-Agent Collaboration",
      "termJa": "人間とエージェントの協働",
      "topicId": "agent-topic-case-studies",
      "meaning": "エージェントと人間の役割分担、ヒューマンインザループの設計、レビューモデルとアシスタントモデル。",
      "relatedTermIds": ["agent-term-human-in-loop", "agent-term-guardrails"]
    }
  ],
  "terms": [
    {
      "id": "agent-term-ai-agent",
      "term": "AI Agent",
      "termJa": "AIエージェント",
      "meaning": "LLMを頭脳として、外部ツールの利用・計画の立案・自己修正を自律的に行い、与えられた目標を達成するソフトウェアシステム。単なるチャットボットと異なり、環境を認識し、判断し、行動するループを持つ。",
      "type": "theory",
      "tags": ["基礎", "全章"]
    },
    {
      "id": "agent-term-profile",
      "term": "Agent Profile",
      "termJa": "エージェントプロフィール",
      "meaning": "エージェントの役割・性格・専門領域・行動指針をシステムプロンプトとして定義したもの。プロフィール設計がエージェントの振る舞いの質を大きく左右する。",
      "type": "theory",
      "tags": ["設計", "構成要素"]
    },
    {
      "id": "agent-term-tool-use",
      "term": "Tool Use / Function Calling",
      "termJa": "ツール呼び出し",
      "meaning": "LLMが外部のAPI・データベース・検索エンジン等のツールを呼び出す機能。LLMが「どのツールを」「どの引数で」呼ぶかをJSON形式で出力し、実行結果をLLMに返すことで、LLM単体ではできない操作を実現する。",
      "type": "technique",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-planning",
      "term": "Planning",
      "termJa": "計画（プランニング）",
      "meaning": "エージェントが目標達成のために、タスクを分解し実行順序を決定するプロセス。計画の質がエージェント全体の成否を左右する。事前計画と動的再計画の2種類がある。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-self-correction",
      "term": "Self-Correction",
      "termJa": "自己修正",
      "meaning": "エージェントが自身の出力や行動の結果を評価し、誤りを検出して修正するメカニズム。リトライ、出力の再検証、代替手段への切り替えなどの戦略がある。",
      "type": "technique",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-memory",
      "term": "Agent Memory",
      "termJa": "エージェントメモリ",
      "meaning": "エージェントが過去の経験・会話履歴・学習した知識を保持する仕組み。短期メモリ（現在の会話コンテキスト）と長期メモリ（永続化された知識・経験）に分かれる。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-perception",
      "term": "Perception",
      "termJa": "知覚",
      "meaning": "エージェントが環境からの情報（ユーザー入力、ツール実行結果、外部データ）を受け取り解釈するプロセス。マルチモーダル入力（テキスト・画像・音声）の処理も含む。",
      "type": "theory",
      "tags": ["基礎", "構成要素"]
    },
    {
      "id": "agent-term-agent-tuning",
      "term": "Agent-Tuning",
      "termJa": "エージェントチューニング",
      "meaning": "LLMをエージェントタスクに特化してファインチューニングする手法。ツール呼び出しの精度向上、計画能力の強化などを目的とし、エージェント行動のトレースデータで学習する。推論時のプロンプト設計とは異なるアプローチ。",
      "type": "technique",
      "tags": ["理論", "学習"]
    },
    {
      "id": "agent-term-single-agent",
      "term": "Single-Agent Workflow",
      "termJa": "シングルエージェントワークフロー",
      "meaning": "1つのエージェントが全ての処理を担当するワークフロー。シンプルで管理しやすいが、複雑なタスクでは限界がある。コード生成→実行→リフレクションのサイクルが典型例。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-multi-agent",
      "term": "Multi-Agent Workflow",
      "termJa": "マルチエージェントワークフロー",
      "meaning": "複数の専門エージェントが協調してタスクを遂行するワークフロー。各エージェントに異なる役割を割り当て、連携させることで複雑な問題に対応する。オーケストレーター型、議論型、階層型などのパターンがある。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-chat-completions",
      "term": "Chat Completions API",
      "termJa": "チャット補完API",
      "meaning": "OpenAI等が提供する、会話形式でLLMを呼び出すAPI。system/user/assistantのロールでメッセージを送り、AIの応答を得る。エージェント開発の基盤となるインターフェース。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-reasoning-models",
      "term": "Reasoning Models",
      "termJa": "推論モデル",
      "meaning": "o1、o3等の、内部で段階的な推論プロセスを実行するLLM。通常のモデルより複雑な論理的思考が可能で、計画立案や数学的推論に優れる。エージェントの計画フェーズでの活用が期待される。",
      "type": "theory",
      "tags": ["モデル", "理論"]
    },
    {
      "id": "agent-term-structured-outputs",
      "term": "Structured Outputs",
      "termJa": "構造化出力",
      "meaning": "LLMの出力をJSONスキーマ等の事前定義された形式に強制する機能。エージェントのツール呼び出しや計画出力で、パース可能な安定した出力を保証する。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-prompt-caching",
      "term": "Prompt Caching",
      "termJa": "プロンプトキャッシング",
      "meaning": "同一のプロンプトプレフィックスを再利用し、API呼び出しのコストと遅延を削減する技術。長いシステムプロンプトや大量のコンテキストを使うエージェントで特に有効。",
      "type": "technique",
      "tags": ["開発", "最適化"]
    },
    {
      "id": "agent-term-code-interpreter",
      "term": "Code Interpreter",
      "termJa": "コードインタープリタ",
      "meaning": "AIが生成したプログラムコードをサンドボックス環境で実行し、結果を取得する仕組み。データ分析、数値計算、ファイル変換など、LLMの計算能力を補完するツールとして使われる。",
      "type": "technique",
      "tags": ["ツール", "実行環境"]
    },
    {
      "id": "agent-term-embedding-api",
      "term": "Embedding API",
      "termJa": "エンベディングAPI",
      "meaning": "テキストをベクトル（数値の配列）に変換するAPI。意味的に近いテキスト同士が近いベクトルになる性質を利用し、セマンティック検索やRAGの基盤技術として使われる。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-assistants-api",
      "term": "Assistants API",
      "termJa": "アシスタントAPI",
      "meaning": "OpenAIが提供する、ステートフルなAIアシスタントを構築するためのAPI。スレッド管理、ファイル処理、Code Interpreter、Function Callingを統合的に提供する。",
      "type": "technique",
      "tags": ["開発", "API"]
    },
    {
      "id": "agent-term-langgraph",
      "term": "LangGraph",
      "termJa": "LangGraph",
      "meaning": "LangChainチームが開発した、グラフベースのエージェントワークフロー構築フレームワーク。ステートマシンとしてエージェントの状態遷移を定義し、条件分岐・ループ・人間の介入を含む複雑なワークフローを構築できる。",
      "type": "technique",
      "tags": ["フレームワーク", "開発"]
    },
    {
      "id": "agent-term-mcp",
      "term": "Model Context Protocol (MCP)",
      "termJa": "モデルコンテキストプロトコル",
      "meaning": "Anthropicが提唱する、AIモデルと外部ツール・データソースを標準的な方法で接続するオープンプロトコル。USBのように、様々なツールをエージェントに統一的なインターフェースで接続できる。",
      "type": "technique",
      "tags": ["プロトコル", "ツール"]
    },
    {
      "id": "agent-term-plan-and-execute",
      "term": "Plan-and-Execute",
      "termJa": "計画実行型",
      "meaning": "まず全体計画を立て、その計画に基づいてサブタスクを順次実行するエージェントパターン。計画フェーズと実行フェーズを分離することで、複雑なタスクを体系的に処理する。実行結果に応じた計画の修正（再計画）も含む。",
      "type": "technique",
      "tags": ["パターン", "設計"]
    },
    {
      "id": "agent-term-reflection",
      "term": "Reflection",
      "termJa": "リフレクション",
      "meaning": "エージェントが自身の出力を振り返り、品質を評価・改善するプロセス。コード生成後にエラーを検出して修正する、回答の正確性を自己チェックするなど。自己修正の具体的な実装手法の一つ。",
      "type": "technique",
      "tags": ["パターン", "品質"]
    },
    {
      "id": "agent-term-e2b",
      "term": "E2B (Code Sandbox)",
      "termJa": "E2B（コードサンドボックス）",
      "meaning": "AIが生成したコードを安全に実行するためのクラウドサンドボックス環境。ホストシステムから隔離された環境でコードを実行し、結果を取得する。データ分析エージェントでの活用が代表的。",
      "type": "technique",
      "tags": ["ツール", "実行環境"]
    },
    {
      "id": "agent-term-langgraph-studio",
      "term": "LangGraph Studio",
      "termJa": "LangGraph Studio",
      "meaning": "LangGraphで構築したエージェントワークフローを視覚的にデバッグ・テストするためのツール。グラフの状態遷移をリアルタイムで確認でき、各ノードの入出力を検査できる。",
      "type": "technique",
      "tags": ["ツール", "デバッグ"]
    },
    {
      "id": "agent-term-local-llm",
      "term": "Local LLM",
      "termJa": "ローカルLLM",
      "meaning": "Ollama等を使いローカル環境で動作させるLLM。API費用がかからず、データがローカルに留まるため機密性が高い。ただし、モデルサイズやGPUリソースによる性能の制約がある。",
      "type": "technique",
      "tags": ["開発", "モデル"]
    },
    {
      "id": "agent-term-ai-workflow",
      "term": "AI Workflow",
      "termJa": "AIワークフロー",
      "meaning": "LLMの呼び出しとツール実行を、事前定義されたフローに基づいて制御する仕組み。エージェントほど自律的ではないが、予測可能性が高く、特定の業務プロセスの自動化に適している。エージェントの構成要素としても使われる。",
      "type": "theory",
      "tags": ["設計", "ワークフロー"]
    },
    {
      "id": "agent-term-evaluation",
      "term": "Agent Evaluation",
      "termJa": "エージェント評価",
      "meaning": "AIエージェントの性能を定量的・定性的に評価するプロセス。エージェント能力（ツール使用、計画、記憶）と問題解決能力（タスクの完了度、正確性）の2軸で評価する。",
      "type": "theory",
      "tags": ["評価", "運用"]
    },
    {
      "id": "agent-term-llm-judge",
      "term": "LLM-as-a-Judge",
      "termJa": "LLMによる評価",
      "meaning": "LLM自体を評価者として使い、エージェントの出力品質を自動評価する手法。人間の評価と相関が高い場合が多く、大量のテストケースの評価を効率化できる。ただし、評価LLM自体のバイアスに注意が必要。",
      "type": "technique",
      "tags": ["評価", "手法"]
    },
    {
      "id": "agent-term-task-domain-space",
      "term": "Task Space / Domain Space",
      "termJa": "タスク空間・ドメイン空間",
      "meaning": "エージェントの評価における2つの次元。タスク空間はエージェントが解くべき問題の種類と複雑さ、ドメイン空間は業務領域固有の知識や制約を表す。評価設計時に両方をカバーすることが重要。",
      "type": "theory",
      "tags": ["評価", "理論"]
    },
    {
      "id": "agent-term-error-analysis",
      "term": "Error Analysis",
      "termJa": "エラー分析",
      "meaning": "エージェントの失敗パターンを体系的に分類・分析する手法。計画・推論エラー、行動・実行エラー、環境・知覚エラー、マルチエージェント連携エラーの4カテゴリで整理し、改善に活かす。",
      "type": "technique",
      "tags": ["評価", "改善"]
    },
    {
      "id": "agent-term-agent-ux",
      "term": "Agent UX",
      "termJa": "エージェントUX",
      "meaning": "AIエージェントとユーザーの間のインタラクション設計。エージェントの処理過程の可視化、信頼性の構築、ユーザーの承認・介入ポイントの設計など、従来のUI/UXとは異なる設計原則が求められる。",
      "type": "theory",
      "tags": ["運用", "UX"]
    },
    {
      "id": "agent-term-prompt-injection",
      "term": "Prompt Injection",
      "termJa": "プロンプトインジェクション",
      "meaning": "悪意のある入力によってエージェントの指示を上書きし、意図しない動作を引き起こす攻撃手法。間接的プロンプトインジェクション（外部データ経由）は特に防御が難しく、エージェントのセキュリティ設計で最重要課題の一つ。",
      "type": "theory",
      "tags": ["セキュリティ", "リスク"]
    },
    {
      "id": "agent-term-agentops",
      "term": "AgentOps",
      "termJa": "AgentOps",
      "meaning": "AIエージェントの運用を監視・管理するための概念・ツール群。エージェントの実行トレース、コスト追跡、パフォーマンス計測、異常検知などを包括的に行う。MLOpsのエージェント版。",
      "type": "technique",
      "tags": ["運用", "モニタリング"]
    },
    {
      "id": "agent-term-langsmith",
      "term": "LangSmith",
      "termJa": "LangSmith",
      "meaning": "LangChainチームが提供する、LLMアプリケーションの開発・テスト・モニタリングプラットフォーム。エージェントの実行トレースの可視化、プロンプトの管理、評価データセットの作成・実行が可能。",
      "type": "technique",
      "tags": ["ツール", "モニタリング"]
    },
    {
      "id": "agent-term-prompt-flow-tracing",
      "term": "Prompt Flow Tracing",
      "termJa": "Prompt Flow トレーシング",
      "meaning": "Microsoftが提供するPrompt flowのトレース機能。エージェントの各ステップ（LLM呼び出し、ツール実行、判断分岐）をDAGとして可視化し、ボトルネックの特定やデバッグに活用する。",
      "type": "technique",
      "tags": ["ツール", "モニタリング"]
    },
    {
      "id": "agent-term-human-in-loop",
      "term": "Human-in-the-Loop",
      "termJa": "ヒューマンインザループ",
      "meaning": "エージェントの処理フローに人間の判断・承認ポイントを組み込む設計パターン。重要な意思決定や不可逆な操作の前に人間の確認を挟むことで、エージェントの安全性と信頼性を確保する。",
      "type": "technique",
      "tags": ["設計", "安全性"]
    },
    {
      "id": "agent-term-guardrails",
      "term": "Guardrails",
      "termJa": "ガードレール",
      "meaning": "エージェントの行動を安全な範囲内に制限する仕組み。入力のフィルタリング、出力の検証、許可されたアクションのホワイトリスト、コスト上限の設定など、多層的な防御を構築する。",
      "type": "technique",
      "tags": ["安全性", "運用"]
    },
    {
      "id": "agent-term-arch-self-improvement",
      "term": "Agent Architecture Self-Improvement",
      "termJa": "エージェントの自己改善",
      "meaning": "エージェントが運用中の経験から学び、プロンプト・ツール選択・ワークフロー自体を改善する仕組み。メモリに蓄積された成功・失敗パターンを活用し、継続的にパフォーマンスを向上させる。",
      "type": "technique",
      "tags": ["運用", "改善"]
    },
    {
      "id": "agent-term-role-playing",
      "term": "Role-Playing Agent",
      "termJa": "ロールプレイングエージェント",
      "meaning": "特定の人物像（ペルソナ）の役割を演じるエージェント。マーケティングではターゲット顧客を模擬し、コンテンツの評価やフィードバックを行う。複数ペルソナのエージェントによるディスカッションも可能。",
      "type": "technique",
      "tags": ["パターン", "活用"]
    },
    {
      "id": "agent-term-personalization",
      "term": "Personalization Agent",
      "termJa": "パーソナライズエージェント",
      "meaning": "ユーザーの属性・行動履歴・嗜好に基づき、個別最適化された提案やコンテンツを生成するエージェント。会話を通じてユーザーの潜在ニーズを把握し、従来のルールベースを超えた柔軟なレコメンドを実現する。",
      "type": "technique",
      "tags": ["パターン", "活用"]
    },
    {
      "id": "agent-term-rag-long-context",
      "term": "RAG + Long Context",
      "termJa": "RAGとロングコンテキスト",
      "meaning": "RAG（検索拡張生成）とロングコンテキストモデルの使い分け・併用戦略。ロングコンテキストモデルは大量のテキストを直接入力できるが、コストが高い。RAGは必要な情報のみを検索するため効率的だが、検索精度に依存する。",
      "type": "technique",
      "tags": ["技術", "検索"]
    }
  ]
}
