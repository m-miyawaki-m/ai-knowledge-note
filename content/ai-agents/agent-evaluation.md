---
title: "AIエージェントの評価"
tags: [評価, 運用, 理論, 手法, 改善]
created: 2026-02-25
updated: 2026-02-26
---

## エージェント評価の2つの軸

[[エージェント評価]]は2つの軸で考えます。(1)エージェント能力の評価：ツール使用の正確性、計画の適切さ、自己修正の有効性、メモリの活用度など、エージェントの構成要素ごとの性能を測る。(2)問題解決能力の評価：最終的なタスク達成度を測る。正答率、完了率、ユーザー満足度など。[[タスク空間とドメイン空間]]の概念も重要で、タスク空間は「何をさせるか」の多様性（簡単な質問→複雑な多段階タスク）、ドメイン空間は「どの業務領域か」の範囲（IT、法務、医療等）を表します。評価はこの2次元をバランスよくカバーする必要があります。

## 評価指標

エージェント能力の指標として、(1)ツール選択の正確性（正しいツールを正しい引数で呼べたか）、(2)計画の妥当性（サブタスクの分解が適切か）、(3)自己修正の成功率（エラーから回復できたか）。問題解決能力の指標として、(1)タスク完了率、(2)回答の正確性・完全性、(3)ユーザー満足度。運用指標として、(1)レイテンシ（応答時間）、(2)コスト（API呼び出し回数・トークン数）、(3)安全性（不適切な回答の発生率）。これらの指標を組み合わせて、エージェントの総合的な品質を評価します。

## LLM-as-a-Judgeと評価の準備

[[LLM-as-a-Judge]]は、LLM自体を評価者として使い、エージェントの出力品質を自動評価する手法です。評価プロンプトに評価基準と被評価テキストを入力し、スコアや判定を出力させます。人間の評価と相関が高い場合が多く、大量のテストケースの評価を効率化できます。ただし、(1)評価LLM自体のバイアス（自分が生成した回答を高く評価しがち）、(2)評価基準の曖昧さ、(3)文化的・言語的な偏り、に注意が必要です。評価の準備として、代表的なテストケースの作成、期待出力（ゴールドスタンダード）の定義、評価プロンプトの設計とキャリブレーションを行います。

## エラー分析パターン

[[エラー分析]]はエージェントの失敗を体系的に分類し、改善に活かす手法です。(1)計画・推論エラー：タスクの分解が不適切、サブタスクの順序が誤り、不要なステップの追加。(2)行動・実行エラー：誤ったツールの選択、引数の誤り、APIエラーのハンドリング失敗。(3)環境・知覚エラー：ツール実行結果の誤解釈、ユーザー意図の取り違え、コンテキストの見落とし。(4)マルチエージェントエラー：エージェント間の情報伝達の齟齬、責任範囲の重複・隙間、デッドロック。各カテゴリの頻度と影響度を分析し、最も効果的な改善箇所を特定します。

## 用語

- **Agent Evaluation（エージェント評価）**: AIエージェントの性能を定量的・定性的に評価するプロセス。エージェント能力（ツール使用、計画、記憶）と問題解決能力（タスクの完了度、正確性）の2軸で評価する。
- **Task Space / Domain Space（タスク空間・ドメイン空間）**: エージェントの評価における2つの次元。タスク空間はエージェントが解くべき問題の種類と複雑さ、ドメイン空間は業務領域固有の知識や制約を表す。評価設計時に両方をカバーすることが重要。
- **LLM-as-a-Judge（LLMによる評価）**: LLM自体を評価者として使い、エージェントの出力品質を自動評価する手法。人間の評価と相関が高い場合が多く、大量のテストケースの評価を効率化できる。ただし、評価LLM自体のバイアスに注意が必要。
- **Error Analysis（エラー分析）**: エージェントの失敗パターンを体系的に分類・分析する手法。計画・推論エラー、行動・実行エラー、環境・知覚エラー、マルチエージェント連携エラーの4カテゴリで整理し、改善に活かす。
